{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import random\n",
    "#import dotenv\n",
    "#load env from .env\n",
    "#dotenv.load_dotenv()\n",
    "bedrock_runtime = boto3.client('bedrock-runtime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "from anthropic_bedrock import AnthropicBedrock\n",
    "anthropic_bedrock = AnthropicBedrock(\n",
    "    aws_region='us-east-1',\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "def num_tokens_from_string(text, model_name):\n",
    "    if model_name.startswith(\"gpt\"):\n",
    "        # encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "        pass\n",
    "        # num_tokens = len(encoding.encode(text))\n",
    "    elif model_name.startswith(\"claude\"):\n",
    "        num_tokens = anthropic_bedrock.count_tokens(text)  # \n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_community.chat_models import BedrockChat\n",
    "from langchain_core.messages import HumanMessage,AIMessage\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder,HumanMessagePromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llm_sonnet = BedrockChat(model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\",\n",
    "                  model_kwargs={\"temperature\": 0.2,\n",
    "                                \"top_k\":250,\n",
    "                                \"max_tokens\": 1024,\n",
    "                                \"top_p\":0.95,\n",
    "                                # \"stop_sequences\":['</response>']\n",
    "                               },\n",
    "                  streaming=False,callbacks=[StreamingStdOutCallbackHandler()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_extract = \\\n",
    "\"\"\"\n",
    "You are helpful assistant who is an expert in natural language processing and especially Named entity recognition.\n",
    "Create a JSON response that categorizes words from the provided text into specific keys.\n",
    "The keys should include People, Country, Location,  City, Manufacturer, Brand, Datetime, Event, and Other.\n",
    "please enclose the answer in xml tag <output>\n",
    "\n",
    "The values of these keys should be lists containing relevant words from the input text.\n",
    "Example:\n",
    "input text: 我想了解海尔在美国有关新品发布的新闻报道\n",
    "<output>\n",
    "{{\n",
    "\"brand\":\"海尔\",\n",
    "\"country\":\"美国\",\n",
    "\"event\":\"新品发布\",\n",
    "}}\n",
    "</output>\n",
    "\n",
    "Here is user's input text:\n",
    "<query>\n",
    "{query}\n",
    "</query>\n",
    "\n",
    "Skip the preamble, go straight into the answer.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_code = \\\n",
    "\"\"\"\n",
    "You are developer of mastering Elasticsearch, now you are developing application on Elasticsearch,\n",
    "Here is the schema of the Elasticsearch you can refer to:\n",
    "<schema>\n",
    "{schema}\n",
    "</schema>\n",
    "\n",
    "Here is the user's query and keywords extracted from the query you can use:\n",
    "<query>\n",
    "{query}\n",
    "</query>\n",
    "\n",
    "<keywords>\n",
    "{keywords}\n",
    "</keywords>\n",
    "\n",
    "please translate user's query to Elasticsearch DSL (Domain Specific Language) for query the data in Elasticsearch engine.\n",
    "please enclose the answer in xml tag <output>\n",
    "Skip the preamble, go straight into the answer.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = \\\n",
    "    \"\"\"\n",
    "    字段名 | 数据类型 | 字段说明 |\n",
    "---|--- | ---\n",
    "gather.site_name | keyword | 网站名称 :'新浪网'\n",
    "gather.site_domain | keyword | 网站主域名 ：'sina.com.cn'\n",
    "gather.site_country | keyword | 网站所在国家 :'中国'\n",
    "gather.site_location | keyword | 网站归属地 ：'北京'\n",
    "gather.site_lang_code | keyword | 网站使用语言代码,  采用ISO639-1标准\n",
    "gather.ICP | keyword | 网站ICP： '粤B2-20090059-5'\n",
    "gather.gtime | timestamp | 采集时间，时间戳\n",
    "gather.config_id | keyword | 配置id\n",
    "gather.data_type | keyword | 数据来源类型\n",
    "gather._data_type | keyword | 兼容秘书data_type字段\n",
    "gather.site_level.weight  | byte | 网站分级,取值范围[0,9]:\n",
    "gather.site_level.name | keyword | 网站分级名称\n",
    "gather.info_flag | array<keyword> |  '01'：新闻  '02'：论坛  '03'：博客  '04'：微博 '0401':新浪微博 '0408'：新浪长微博 '0105'：平媒 '06'：微信 '07'： 视频 '0109'：APP '11'： 小视频 '12'：境外资讯 '1201': 境外 '1202'：外文 '13': 境外社交媒体 '1301': Twitter '1302': Facebook  '99':搜索 '17':电视监控 info_flag是array类型,如微博info_flag:[04, 0401]\n",
    "uuid | keyword | 文章uuid\n",
    "url  | keyword | 文章格式化后的链接\n",
    "title   | text | 标题\n",
    "content   | text | 内容\n",
    "ctime   | timestamp | 发布时间\n",
    "channel | keyword | 频道\n",
    "breadcrump | array<keyword> | 面包屑:  ['天涯论坛', '经济论坛']\n",
    "layout_num | keyword | 信息为平煤时，所在版面\n",
    "article_keywords | array<keyword> | 文章标签、关键词\n",
    "meta_keywords | text | 对应html meta标签中keywords属性\n",
    "repost_source | keyword | 文章来源、转载来源\n",
    "repost_count | integer | 转发数\n",
    "reply_count | integer | 评论数\n",
    "visit_count | integer | 阅读数、播放数\n",
    "like_count | integer | 点赞数\n",
    "share_count | integer | 分享数\n",
    "bullet_count | integer | 弹幕数\n",
    "coins_count | integer | 硬币数\n",
    "zaikan_count | integer | 在看数 (微信在看数据)\n",
    "appear_time | date | 时间戳，弹幕弹出时间\n",
    "collection_count | integer | 收藏数\n",
    "edit_count | integer |发生编辑次数、内容编辑次数\n",
    "is_junk | integer | 是否是垃圾网站、无价值数据\n",
    "duration | integer | 视频长度。单位为秒\n",
    "music_id | keyword | 音乐id。短视频中背景音乐id\n",
    "pid | keyword | 转发、转载、评论等信息的 上一级信息id\n",
    "rootid | keyword |评论信息中，用于标记多级评论信息的根信息id。 例如：一条微博有多条评论，其中一条评论(id=011)又被多人评论， 这些子评论的rootid就是011\n",
    "wtype | byte | 发表类型:    1: 原创   2: 转发  7: 评论  8:弹幕   9: 转载  21: 原创保护<微信>\n",
    "place | keyword | 签到地点\n",
    "surface_img |  |封面图片url\n",
    "star_surface_img |  |封面图片下载后，保存在星光服务器上的url;\n",
    "device | keyword | 发帖设备\n",
    "is_toutiao | byte | 是否是头条（注：主要是微信）  0:否  1:头条、置顶 2:精华帖 4:满级精华 5:推荐 6:首页推荐 7:作者认证  支持array类型：[2, 6]表示同时是精华帖和首页推荐\n",
    "is_purchased | byte | 是否付费  1:需要\n",
    "deleted | byte | 是否以删除： 0: 正常访问  1:已删除 2:设置访问权限\n",
    "pic_urls |  | 图片链接,可以是多个   ['http://weibo.com/1.jpg',   'http://tieba.baidu.com/1.jpg']\n",
    "video_urls | | 视频链接,可以是多个 ['http://weibo.com/a/b.mp4',]\n",
    "has_attributes | array<keyword> | 内容标注：   has_pic:包含图片  has_videos:包含视频  has_slink:包含短链   \n",
    "translation | array<object> | 翻译结果  包含 title, content, lang_code, title_server, content_server字段;    [{  'content':'这个建筑',  'title':'河流',  'lang_code':'zh_cn',  'title_server':2,   'content_server':1  }]\n",
    "translation.lang_code | keyword | 翻译语言代码,默认为zh-cn\n",
    "translation.title | text | 标题翻译后结果\n",
    "translation.content | text | 内容翻译后结果\n",
    "translation.title_server | byte | 翻译方式： 1. 百度；  2. 谷歌；  3. 民族翻译据；  4. 自建翻译；  5. 新译\n",
    "translation.content_server | byte | 翻译方式\n",
    "captions | array<object> | 字幕或者语音识结果  [{   'detail': [   {   \"start\": 12.3,     \"dur\": 8.7,     \"text\": 'hello'   ] }   \"language_code\": \"en\"  }]\n",
    "captions.detail.start | integer | 开始时间，取相对时间\n",
    "captions.detail.dur | integer | 时间跨度\n",
    "captions.detail.text | text | 字幕内容、语音识别结果\n",
    "captions.language_code | keyword | 语言编码\n",
    "data_subscribe.customer_id_list | array[string] | 对上的道丁客户id(全局唯一)\n",
    "data_subscribe.d_id_list | array[string] | 对上的道丁账号id(全局唯一)\n",
    "data_subscribe.user_id_list | array[string] | 对上的数据平台用户id\n",
    "data_subscribe.user_subject_id_list | array[string] | 对上的数据平台用户专题id(全局唯一)\n",
    "slink_info | array<object> | 短链信息\n",
    "slink_info.display_name | keyword | 显示名称\n",
    "slink_info.summary | keyword | 短链备注,描述信息\n",
    "slink_info.ct | timestamp | 短链接创建时间\n",
    "slink_info.url_short | keyword | 短链接\n",
    "slink_info.url_long | keyword | 原始链接\n",
    "slink_info.object_type | keyword | 链接类型,如:   link : 链接    webpage : 网页    place : 签到地点    cardlist    video : 视频    collection\n",
    "editors | array<keyword> | 编辑\n",
    "author  | array<keyword> | 作者. 保存新闻(非自媒体)、微信中的作者信息 |\n",
    "publisher.name | keyword | 发布者名称 |\n",
    "publisher.id | keyword | 发布者id |\n",
    "publisher.platform | keyword | 发布平台   自媒体、新闻、平媒 |\n",
    "publisher.entity | keyword | 发布主体 |\n",
    "publisher.site_name | keyword | 发布网站名称 |\n",
    "user.name | keyword | 用户名 |\n",
    "user.nickname | keyword | 用户昵称\n",
    "user.uid | keyword | 用户uid\n",
    "user.url | keyword | 用户个人主页地址\n",
    "user.gender | keyword | 用户性别： 'm':男  'f':女 'n':未知\n",
    "user.profile_img_url | keyword | 用户头像url\n",
    "user.friends_count | integer | 用户关注数\n",
    "user.followers_count | integer | 用户粉丝数\n",
    "user.bi_followers_count | integer | 用户的互粉数\n",
    "user.statuses_count | integer | 用户发文数\n",
    "user.visit_count | integer | 用户作品总访问数、播放量\n",
    "user.like_count | integer | 用户作品总获赞数、喜欢数\n",
    "user.created_at | integer | 用户注册时间\n",
    "user.location | array<keyword> | 用户地域，采集所得数据 ['上海', '静安区']\n",
    "user.country | keyword | 用户所在国家,标准化后的数据\n",
    "user.province | keyword | 用户所在省份,标准化后的数据\n",
    "user.city | keyword | 用户所在区县,标准化后的数据\n",
    "user.level | integer | 用户级别\n",
    "user.verified | byte | 用户是否认证: 0:未认证 1:普通认证(对应微博橙v) 2:机构认证(对应微博蓝v)\n",
    "user.verified_type | short | 认证类型 -1:普通用户 0:名人 1:政府 2:企业 3：媒体 4:校园 5:网站 6:应用 7:团体(机构) 8:待审企业 10:类政府 200:初级达人 220:中高级达人 400:已故V用户\n",
    "user.verified_reason | object | 认证描述、认证原因\n",
    "user.description | text | 用户描述、个人简介\n",
    "user.ip_region|array<string>|ip属地（注：暂支持的有 微博、微信、头条、知乎）\n",
    "user.kwaiId | string | 快手号\n",
    "analysis.sentiment | integer | 正负面： -6:确定负面(高敏感) -5:确定负面(敏感) -2:确定负面 -1:疑似负面 0:中性 1:疑似正面 2:确定正面 9：争议 \n",
    "analysis.noise | integer | 噪音  0: 非噪音  1:噪音\n",
    "analysis.keywords | array<object> | 分析所得关键词  [ {'word':‘电视剧’},    {'word':‘偶像’}  ]\n",
    "analysis.hashcode.1 | float | 雷同数据排重，用于排除雷同数据;ti+cn+siteName=>hash(排重)\n",
    "analysis.hashcode.2 | float | hash2:近似数据排重，用于聚合几乎相同数据;title 5个关键词计算HASH\n",
    "analysis.hashcode.3 | float | hash3:相同主题排重，用户聚合相同主题数据; kw5 5个关键词计算HASH\n",
    "analysis.hashcode.4 | float | hash4:事件聚合指纹，用户聚合同一事件数据; sim_hash2(事件分类hash值)\n",
    "analysis.hashcode.5 | float | hash5:宽泛主题分类，用户聚合类似主题数据; kw5结果排序去掉后面2个词，再计算一次hash值\n",
    "analysis.tag | array<object> | 标签字段 [{'cid':‘12’, 'tid':‘23’, ‘words’:['北京', '海淀']}]\n",
    "analysis.tag.cid | keyword | 标签对应客户id\n",
    "analysis.tag.tid | keyword | 标签id\n",
    "analysis.tag.words | keyword | 匹配词\n",
    "analysis.classification | array<object> | 系统自动分类[{'name':'金融'，'weight':80}]\n",
    "analysis.classification.name | keyword | 自动分类结果名称: 如汽车、金融\n",
    "analysis.classification.weight | byte | 自动分类权重[0, 100]，取整数\n",
    "retweeted | object | 转发信息中，原发(被转)文章信息； 评论数据中，主贴或原文信息； 字段定义同原文信息，参见上面字段定义\n",
    "analysis.find_address.province | array | 省份列表(从信息中通过地域识别获取): ['河南省', '湖北省']\n",
    "analysis.find_address.city | array | 城市列表(从信息中通过地域识别获取): ['武汉市', '郑州市']0\n",
    "analysis.find_address.district | array | 地区列表(从信息中通过地域识别获取): ['吉利区', '金水区']\n",
    "analysis.find_address.province_count | integer | 地域识别：省份个数\n",
    "analysis.find_address.city_count | integer | 地域识别：城市个数\n",
    "analysis.find_address.district_count | integer | 地域识别：区县个数\n",
    "analysis.info_src.cls.name | array<keyword> | 信源分类名称\n",
    "analysis.info_src.cls.level | keyword | 信源分类级别\n",
    "analysis.info_src.loc.name | array<keyword> | 信源所属地域\n",
    "analysis.info_src.loc.level | keyword | 信源所属地域级别\n",
    "analysis.info_src.lv.name | keyword | 信源分级名称\n",
    "analysis.info_src.lv.level | keyword | 信源分级级别\n",
    "analysis.info_src.type | keyword | 匹配规则类型；1：域名匹配  2：自媒体账号匹配\n",
    "analysis.info_src.domain | keyword | 匹配规则时对应的domain信息\n",
    "analysis.info_src.name | keyword | 网站名、板块名、频道名\n",
    "analysis.hashtag | array | 微博话题\n",
    "analysis.mentions | array | 微博中被 @ 的用户\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_extract = ChatPromptTemplate.from_template(template_extract)\n",
    "prompt_code = ChatPromptTemplate.from_template(template_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers.base import BaseOutputParser\n",
    "import re\n",
    "from operator import itemgetter\n",
    "class CustOuputParser(BaseOutputParser[str]):\n",
    "\n",
    "    def extract(self,content:str) -> str:\n",
    "        pattern = r\"<output>(.*?)</output>\"\n",
    "        match = re.search(pattern, content, re.DOTALL)\n",
    "        return match.group(1) if match else 'Empty'      \n",
    "    \n",
    "    def parse(self, text: str) -> str:\n",
    "        cleaned_text = self.extract(text)\n",
    "        return cleaned_text\n",
    "\n",
    "    @property\n",
    "    def _type(self) -> str:\n",
    "        return \"cust_output_parser\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = CustOuputParser()\n",
    "\n",
    "llm = llm_sonnet\n",
    "chain_1 = prompt_extract | llm |output_parser\n",
    "chain_2 = prompt_code | llm|output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_3 = ({'keywords':chain_1,'query':itemgetter('query'),\"schema\":itemgetter('schema')})|prompt_code|llm|output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"我想了解最近一个月美国媒体关于海尔的负面新闻报道\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n{\\n\"Brand\": [\"海尔\"],\\n\"Country\": [\"美国\"],\\n\"Datetime\": [\"最近一个月\"],\\n\"Event\": [\"负面新闻报道\"]\\n}\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_1.invoke({\"query\":query,\"schema\":schema})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = chain_3.invoke({\"query\":query,\"schema\":schema})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{\n",
      "  \"query\": {\n",
      "    \"bool\": {\n",
      "      \"must\": [\n",
      "        {\n",
      "          \"match\": {\n",
      "            \"gather.site_country\": \"美国\"\n",
      "          }\n",
      "        },\n",
      "        {\n",
      "          \"match_phrase\": {\n",
      "            \"content\": \"海尔\"\n",
      "          }\n",
      "        },\n",
      "        {\n",
      "          \"range\": {\n",
      "            \"ctime\": {\n",
      "              \"gte\": \"now-1M/d\",\n",
      "              \"lte\": \"now/d\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        {\n",
      "          \"range\": {\n",
      "            \"analysis.sentiment\": {\n",
      "              \"lte\": -1\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{\n",
      "  \"query\": {\n",
      "    \"bool\": {\n",
      "      \"must\": [\n",
      "        {\n",
      "          \"match_phrase\": {\n",
      "            \"content\": \"海尔\"\n",
      "          }\n",
      "        },\n",
      "        {\n",
      "          \"match_phrase\": {\n",
      "            \"content\": \"营销活动\"\n",
      "          }\n",
      "        },\n",
      "        {\n",
      "          \"range\": {\n",
      "            \"ctime\": {\n",
      "              \"gte\": \"now-90d/d\",\n",
      "              \"lte\": \"now/d\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  },\n",
      "  \"sort\": [\n",
      "    {\n",
      "      \"ctime\": {\n",
      "        \"order\": \"desc\"\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query2 = \"我想了解近期海尔有哪些营销活动\"\n",
    "resp2 = chain_3.invoke({\"query\":query2,\"schema\":schema})\n",
    "print(resp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyautogen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
