{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf8765d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install boto3 langchain langchain_community -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8db72ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646eecb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrock_runtime = boto3.client('bedrock-runtime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e14612",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data_result.csv'\n",
    "# df = pd.read_csv('data_result.csv',nrows=1000)\n",
    "with open(filename) as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e03203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置要选取的连续元素的长度\n",
    "n = 10\n",
    "\n",
    "# 随机选取一个起始索引\n",
    "start_idx = random.randint(0, len(lines) - n)\n",
    "lines[start_idx:start_idx+n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1702e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "extracted_data = []\n",
    "\n",
    "# 提取聊天的正则表达式模式\n",
    "pattern = r'\"m\":\"(.*?)\"'\n",
    "\n",
    "# 过滤出link\n",
    "\n",
    "# 遍历每一行\n",
    "for line in lines:\n",
    "    match = re.search(pattern, line)\n",
    "    if match:\n",
    "        text = match.group(1)\n",
    "        if not text.startswith('link'):\n",
    "            extracted_data.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cc5947",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(extracted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac127acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 随机选取一个起始索引\n",
    "def random_cut_arr(arr,n,seed=1):\n",
    "    random.seed(seed)\n",
    "    start_idx = random.randint(0, len(arr) - n)\n",
    "    return arr[start_idx:start_idx+n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1200d3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_cut_arr(extracted_data,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37876e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_extracted_data = random_cut_arr(extracted_data,500)\n",
    "text = \"\\n\".join(cut_extracted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11947a21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaaf37f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa4d925",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import BedrockChat\n",
    "from langchain_core.messages import HumanMessage,AIMessage\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder,HumanMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e368c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_sonnet = BedrockChat(model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\",\n",
    "                  model_kwargs={\"temperature\": 0,\n",
    "                                \"top_k\":10,\n",
    "                                \"max_tokens\": 1024,\n",
    "                                \"top_p\":0.5,\n",
    "                                # \"stop_sequences\":['</response>']\n",
    "                               },\n",
    "                  streaming=True,callbacks=[StreamingStdOutCallbackHandler()])\n",
    "\n",
    "llm_haiku = BedrockChat(model_id=\"anthropic.claude-3-haiku-20240307-v1:0\",\n",
    "                  model_kwargs={\"temperature\": 0,\n",
    "                                \"top_k\":10,\n",
    "                                \"max_tokens\": 1024,\n",
    "                                \"top_p\":0.5,\n",
    "                                # \"stop_sequences\":['</response>']\n",
    "                               },\n",
    "                  streaming=True,callbacks=[StreamingStdOutCallbackHandler()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baee30ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_extract = \\\n",
    "\"\"\"You are an expert research assistant, tasked with identifying player sentiments regarding certain in-game items, neutral NPCs, and game market activities. \n",
    "\n",
    "Here is a document you will analyze\n",
    "<doc>\n",
    "{context}\n",
    "</doc>\n",
    "\n",
    "Here is a task:\n",
    "First, find the quotes from the document that are most relevant to {topic}, and then print them in numbered order. Quotes should be relatively short.\n",
    "If there are no relevant quotes, write \"No relevant quotes\" instead.\n",
    "please enclose your analysis results in xml tag <response>.\n",
    "\n",
    "for example:\n",
    "<response>\n",
    "1. \"拍卖行多香\" \n",
    "2. \"我拍到好东西了\" \n",
    "3. \"拍卖行太差劲了\" \n",
    "4. \"auction sucks\" \n",
    "5. \"拍卖行有人发包\" \n",
    "</response>\n",
    "\n",
    "Skip the preamble, go straight into the answer.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76207d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_sentiment = \\\n",
    "\"\"\"You are a chat message sentiment classifer\n",
    "\n",
    "Here is a document you will classify the senetiment\n",
    "<doc>\n",
    "{relevant_info}\n",
    "</doc>\n",
    "\n",
    "\n",
    "please list all the content if it is relevant to {topic} and classify the sentiment of each content into [positive,neutral,negative]'\n",
    "\n",
    "Please follow below requirements:\n",
    "1. You will strictly be based on the document in <doc>.\n",
    "2. please enclose your analysis results in xml tag <sentiment>.\n",
    "\n",
    "for example:\n",
    "<sentiment>\n",
    "1. \"拍卖行多香\" [positive]\n",
    "2. \"我拍到好东西了\" [positive]\n",
    "3. \"拍卖行太差劲了\" [negative]\n",
    "4. \"auction sucks\" [negative]\n",
    "5. \"拍卖行有人发包\" [neutral]\n",
    "</sentiment>\n",
    "\n",
    "Skip the preamble, go straight into the answer. \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1add1efa-e01c-45da-8949-b85eee521677",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers.base import BaseOutputParser\n",
    "import re\n",
    "class CustOuputParser(BaseOutputParser[str]):\n",
    "\n",
    "    def extract(self,content:str) -> str:\n",
    "        pattern = r\"<response>(.*?)</response>\"\n",
    "        match = re.search(pattern, content, re.DOTALL)\n",
    "        if match:\n",
    "            text = match.group(1)\n",
    "            text = text.replace('[','(').replace(']',')') ##避免跟sentiment的格式冲突\n",
    "            return text\n",
    "        else:\n",
    "            return 'No relevant quotes'    \n",
    "    \n",
    "    def parse(self, text: str) -> str:\n",
    "        cleaned_text = self.extract(text)\n",
    "        return cleaned_text\n",
    "\n",
    "    @property\n",
    "    def _type(self) -> str:\n",
    "        return \"cust_output_parser\"\n",
    "\n",
    "\n",
    "class CustOuputParser2(BaseOutputParser[str]):\n",
    "\n",
    "    def extract(self,content:str) -> str:\n",
    "        pattern = r\"<sentiment>(.*?)</sentiment>\"\n",
    "        match = re.search(pattern, content, re.DOTALL)\n",
    "        return match.group(1) if match else 'No sentiment'    \n",
    "    \n",
    "    def parse(self, text: str) -> str:\n",
    "        cleaned_text = self.extract(text)\n",
    "        return cleaned_text\n",
    "\n",
    "    @property\n",
    "    def _type(self) -> str:\n",
    "        return \"cust_output_parser\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea71fb61-a093-4c79-8ae0-280d6e35b910",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0a50d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_chunks(arr, n):\n",
    "    chunks = []\n",
    "    for i in range(0, len(arr), n):\n",
    "        chunks.append(arr[i:i+n])\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82656a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = split_into_chunks(extracted_data,2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0403acb-c13a-412d-af51-aac756552703",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"total chunks {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22dbfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text =  \"\\n\".join(chunks[45])\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038dd969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_core.output_parsers import StrOutputParser\n",
    "# prompt = ChatPromptTemplate.from_template(template)\n",
    "prompt_extract = ChatPromptTemplate.from_template(template_extract)\n",
    "prompt_sentiment = ChatPromptTemplate.from_template(template_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f144e41-6388-47d5-85ce-76c25c2f6745",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "from operator import itemgetter\n",
    "## 如果没有相关内容则无须invoke chain2\n",
    "def route(info):\n",
    "    if not 'no relevant quotes' in info['relevant_info'].lower():\n",
    "        return chain_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc312ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = CustOuputParser()\n",
    "output2_parser  = CustOuputParser2()\n",
    "\n",
    "chain_1 = prompt_extract | llm_sonnet |output_parser\n",
    "chain_2 = prompt_sentiment | llm_sonnet|output2_parser\n",
    "# chain_3 = ({'relevant_info':chain_1,'topic':itemgetter('topic')})|prompt_sentiment | llm_haiku|output2_parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400e5a17-fecc-40ea-a35a-c26689fe6a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "##测试chain3\n",
    "# chain_3.invoke({'topic':\"auction house\",\n",
    "#                        'context':text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ef25c2-9076-43e5-8c7c-3f072dc54a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##测试加入了路由选择的chainfull\n",
    "full_chain = ({'relevant_info':chain_1,'topic':itemgetter('topic')})| RunnableLambda(route)\n",
    "answer = full_chain.invoke({'topic':\"auction house\",'context':text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2b0c47-2849-485e-88ef-5aeb45eeb514",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58321e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question = \"is there any content relevant to auction house?\"\n",
    "\n",
    "#'please list all the content if it is relevant and classify the sentiment of each content into [positive,neutral,negative]'\n",
    "\n",
    "# answer = chain_2.invoke({'topic':\"auction house\",\n",
    "#                        'context':text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6087d996-eced-4012-9f71-2706b56f29db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee6ca2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_and_sentiment(text) -> list:\n",
    "    pattern = r'^(.*?)\\s*\\[(.*?)\\]'\n",
    "    # pattern = r'\"(.*?)\"\\s*\\[(.*?)\\]$'\n",
    "    if not text:\n",
    "        return []\n",
    "    result = []\n",
    "    for line in text.split('\\n'):\n",
    "        match = re.match(pattern, line)\n",
    "        if match:\n",
    "            # print(match)\n",
    "            text_part = match.group(1)\n",
    "            quoted_texts = re.findall(r'\"(.*?)\"', text_part)\n",
    "            # print(quoted_texts)\n",
    "            sentiment_part = match.group(2)\n",
    "            result.append((quoted_texts[0], sentiment_part))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca16752",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_text_and_sentiment(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e293a756",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save a list to a local file, if the file is exist then append the list to the file\n",
    "def save_list(list,file_name):\n",
    "    with open(file_name,'a') as f:\n",
    "        for item in list:\n",
    "            f.write(\"%s\\n\" % item)\n",
    "    f.close()\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394e3933",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save a list to a csv file using pandas, if the file is exist then append the list to the file\n",
    "import pandas as pd\n",
    "import os\n",
    "def save_to_csv(data, filename):\n",
    "    new_data = pd.DataFrame(data, columns=['text','sentiment'])\n",
    "    if os.path.isfile(filename):\n",
    "        df = pd.read_csv(filename)\n",
    "        #append data to df\n",
    "        df = pd.concat([df, new_data], ignore_index=True)\n",
    "    else:\n",
    "        df = new_data\n",
    "    df.to_csv(filename, index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd7d833",
   "metadata": {},
   "source": [
    "循环每个chunk进行输出,每次追加到csv文件保存，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53abb20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "all_result = []\n",
    "filename = 'parsed_result'\n",
    "\n",
    "##断点跳过\n",
    "skip_num =238\n",
    "for i,chunk in enumerate(chunks[:1000]):\n",
    "    if i < skip_num:\n",
    "        continue\n",
    "    t1 = time.time()\n",
    "    print(f'--------chunk idx:{i}-------')\n",
    "    text =  \"\\n\".join(chunk)\n",
    "    answer = full_chain.invoke({'topic':\"auction house\",\n",
    "                       'context':text})\n",
    "    extract_ret = extract_text_and_sentiment(answer)\n",
    "    print(f'\\nextract_ret:\\n{extract_ret}')\n",
    "    time.sleep(2)\n",
    "    print(f'---time cost {time.time()-t1} s -----\\nsleep 10s for token tpm\\n\\n')\n",
    "    if extract_ret:\n",
    "        all_result+=extract_ret\n",
    "        save_to_csv(extract_ret,filename+f\"chunk_{i}.csv\")\n",
    "        save_to_csv(extract_ret,filename+f\"_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f31179",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41a5c66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
