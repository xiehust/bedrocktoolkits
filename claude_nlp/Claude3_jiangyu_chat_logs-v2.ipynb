{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7cf8765d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.10/site-packages (1.28.64)\n",
      "Collecting boto3\n",
      "  Using cached boto3-1.34.64-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: langchain in /opt/conda/lib/python3.10/site-packages (0.0.350)\n",
      "Collecting langchain\n",
      "  Using cached langchain-0.1.12-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: langchain_community in /opt/conda/lib/python3.10/site-packages (0.0.7)\n",
      "Collecting langchain_community\n",
      "  Using cached langchain_community-0.0.28-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting botocore<1.35.0,>=1.34.64 (from boto3)\n",
      "  Using cached botocore-1.34.64-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3) (1.0.1)\n",
      "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3)\n",
      "  Downloading s3transfer-0.10.1-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.4.49)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (3.9.1)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.6.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.33)\n",
      "Collecting langchain-core<0.2.0,>=0.1.31 (from langchain)\n",
      "  Using cached langchain_core-0.1.32-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
      "  Using cached langchain_text_splitters-0.0.1-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
      "  Using cached langsmith-0.1.27-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.26.3)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.10.13)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.10/site-packages (from botocore<1.35.0,>=1.34.64->boto3) (2.8.2)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /opt/conda/lib/python3.10/site-packages (from botocore<1.35.0,>=1.34.64->boto3) (1.26.18)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: anyio<5,>=3 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.2.0,>=0.1.31->langchain) (3.7.1)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.2.0,>=0.1.31->langchain) (23.2)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Using cached orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (49 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2023.11.17)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.31->langchain) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.31->langchain) (1.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.64->boto3) (1.16.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Using cached boto3-1.34.64-py3-none-any.whl (139 kB)\n",
      "Using cached langchain-0.1.12-py3-none-any.whl (809 kB)\n",
      "Using cached langchain_community-0.0.28-py3-none-any.whl (1.8 MB)\n",
      "Using cached botocore-1.34.64-py3-none-any.whl (12.0 MB)\n",
      "Using cached langchain_core-0.1.32-py3-none-any.whl (260 kB)\n",
      "Using cached langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
      "Using cached langsmith-0.1.27-py3-none-any.whl (68 kB)\n",
      "Downloading s3transfer-0.10.1-py3-none-any.whl (82 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m82.2/82.2 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
      "Installing collected packages: orjson, langsmith, botocore, s3transfer, langchain-core, langchain-text-splitters, langchain_community, boto3, langchain\n",
      "  Attempting uninstall: langsmith\n",
      "    Found existing installation: langsmith 0.0.85\n",
      "    Uninstalling langsmith-0.0.85:\n",
      "      Successfully uninstalled langsmith-0.0.85\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.31.64\n",
      "    Uninstalling botocore-1.31.64:\n",
      "      Successfully uninstalled botocore-1.31.64\n",
      "  Attempting uninstall: s3transfer\n",
      "    Found existing installation: s3transfer 0.7.0\n",
      "    Uninstalling s3transfer-0.7.0:\n",
      "      Successfully uninstalled s3transfer-0.7.0\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.1.3\n",
      "    Uninstalling langchain-core-0.1.3:\n",
      "      Successfully uninstalled langchain-core-0.1.3\n",
      "  Attempting uninstall: langchain_community\n",
      "    Found existing installation: langchain-community 0.0.7\n",
      "    Uninstalling langchain-community-0.0.7:\n",
      "      Successfully uninstalled langchain-community-0.0.7\n",
      "  Attempting uninstall: boto3\n",
      "    Found existing installation: boto3 1.28.64\n",
      "    Uninstalling boto3-1.28.64:\n",
      "      Successfully uninstalled boto3-1.28.64\n",
      "  Attempting uninstall: langchain\n",
      "    Found existing installation: langchain 0.0.350\n",
      "    Uninstalling langchain-0.0.350:\n",
      "      Successfully uninstalled langchain-0.0.350\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "jupyter-ai 2.8.1 requires faiss-cpu, which is not installed.\n",
      "aiobotocore 2.7.0 requires botocore<1.31.65,>=1.31.16, but you have botocore 1.34.64 which is incompatible.\n",
      "jupyter-ai 2.8.1 requires langchain==0.0.350, but you have langchain 0.1.12 which is incompatible.\n",
      "jupyter-ai 2.8.1 requires langchain-core<0.1.4,>=0.1.0, but you have langchain-core 0.1.32 which is incompatible.\n",
      "jupyter-ai-magics 2.8.1 requires langchain==0.0.350, but you have langchain 0.1.12 which is incompatible.\n",
      "jupyter-ai-magics 2.8.1 requires langchain-core<0.1.4,>=0.1.0, but you have langchain-core 0.1.32 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed boto3-1.34.64 botocore-1.34.64 langchain-0.1.12 langchain-core-0.1.32 langchain-text-splitters-0.0.1 langchain_community-0.0.28 langsmith-0.1.27 orjson-3.9.15 s3transfer-0.10.1\n"
     ]
    }
   ],
   "source": [
    "!pip install boto3 langchain langchain_community -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8db72ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "646eecb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrock_runtime = boto3.client('bedrock-runtime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5e14612",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data_result.csv'\n",
    "# df = pd.read_csv('data_result.csv',nrows=1000)\n",
    "with open(filename) as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75e03203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10217292369193|80|2024-03-01 00:12:32,069|{\"uid\":\"10215984336169\",\"c\":1,\"custom\":\"{\\\\\"mod\\\\\":\\\\\"\\\\\",\\\\\"modPic\\\\\":0,\\\\\"officialTitle\\\\\":-1,\\\\\"clientTime\\\\\":\\\\\"170922315110217292369193\\\\\",\\\\\"responseData\\\\\":null,\\\\\"atData\\\\\":null,\\\\\"modid\\\\\":0}\",\"llm\":\"\",\"m\":\"çœ‹çœ‹æ–°è‹±é›„ï¼Œå†è¯´\",\"group\":\"\"}\\n',\n",
       " '10833625353658|55|2024-03-01 00:12:32,014|{\"uid\":\"\",\"c\":2,\"custom\":\"{\\\\\"mod\\\\\":\\\\\"\\\\\",\\\\\"modPic\\\\\":0,\\\\\"officialTitle\\\\\":-1,\\\\\"clientTime\\\\\":\\\\\"170922315010833625353658\\\\\",\\\\\"responseData\\\\\":null,\\\\\"atData\\\\\":null,\\\\\"modid\\\\\":0}\",\"llm\":\"\",\"m\":\"å¤©ç‰§æœ‰ç”¨å—ç©ºå†›ï¼Ÿ\",\"group\":\"\"}\\n',\n",
       " '745723672552|100|2024-03-01 00:12:32,778|{\"uid\":\"819098683576\",\"c\":1,\"custom\":\"{\\\\\"mod\\\\\":\\\\\"\\\\\",\\\\\"modPic\\\\\":0,\\\\\"officialTitle\\\\\":-1,\\\\\"clientTime\\\\\":\\\\\"1709223152745723672552\\\\\",\\\\\"responseData\\\\\":null,\\\\\"atData\\\\\":null,\\\\\"modid\\\\\":0}\",\"llm\":\"\",\"m\":\"ç¬¬äºŒä¹Ÿè¡Œäº†\",\"group\":\"\"}\\n',\n",
       " '10568238501250|80|2024-03-01 00:12:32,048|{\"uid\":\"10545092103554\",\"c\":1,\"custom\":\"{\\\\\"mod\\\\\":\\\\\"\\\\\",\\\\\"modPic\\\\\":0,\\\\\"officialTitle\\\\\":2,\\\\\"clientTime\\\\\":\\\\\"170922315210568238501250\\\\\",\\\\\"responseData\\\\\":null,\\\\\"atData\\\\\":null,\\\\\"modid\\\\\":0}\",\"llm\":\"\",\"m\":\"ä½ è·Ÿè½¦ä¹Ÿè·Ÿç­‰çº§é«˜çš„ï¼Œç»™çš„å¡å¤š\",\"group\":\"\"}\\n',\n",
       " '8018900159741|80|2024-03-01 00:12:31,300|{\"uid\":\"\",\"c\":2,\"custom\":\"{\\\\\"mod\\\\\":\\\\\"\\\\\",\\\\\"modPic\\\\\":0,\\\\\"officialTitle\\\\\":-1,\\\\\"clientTime\\\\\":\\\\\"17092231508018900159741\\\\\",\\\\\"responseData\\\\\":null,\\\\\"atData\\\\\":null,\\\\\"modid\\\\\":0}\",\"llm\":\"\",\"m\":\"Watch multiple red lines appear\",\"group\":\"\"}\\n',\n",
       " '8018900159741|80|2024-03-01 00:12:32,897|{\"uid\":\"102_2_3325_500323347\",\"c\":2,\"custom\":\"{\\\\\"mod\\\\\":\\\\\"\\\\\",\\\\\"modPic\\\\\":0,\\\\\"officialTitle\\\\\":-1,\\\\\"clientTime\\\\\":\\\\\"17092231518018900159741\\\\\",\\\\\"responseData\\\\\":null,\\\\\"atData\\\\\":null,\\\\\"modid\\\\\":0}\",\"llm\":\"{\\\\\"t\\\\\":2,\\\\\"iconIDs\\\\\":\\\\\"49\\\\\",\\\\\"iconID\\\\\":\\\\\"49\\\\\",\\\\\"uts\\\\\":1}\",\"m\":\"link49\",\"group\":\"\"}\\n',\n",
       " '325055939325|100|2024-03-01 00:12:31,724|{\"uid\":\"404699088153\",\"c\":1,\"custom\":\"{\\\\\"mod\\\\\":\\\\\"\\\\\",\\\\\"modPic\\\\\":0,\\\\\"officialTitle\\\\\":-1,\\\\\"clientTime\\\\\":\\\\\"1709223151325055939325\\\\\",\\\\\"responseData\\\\\":null,\\\\\"atData\\\\\":null,\\\\\"modid\\\\\":0}\",\"llm\":\"\",\"m\":\"Let me in. plz\",\"group\":\"\"}\\n',\n",
       " '10094962937100|80|2024-03-01 00:12:34,544|{\"uid\":\"\",\"c\":2,\"custom\":\"{\\\\\"mod\\\\\":\\\\\"\\\\\",\\\\\"modPic\\\\\":0,\\\\\"officialTitle\\\\\":2,\\\\\"clientTime\\\\\":\\\\\"170922315310094962937100\\\\\",\\\\\"responseData\\\\\":null,\\\\\"atData\\\\\":null,\\\\\"modid\\\\\":0}\",\"llm\":\"\",\"m\":\"ç”µç«™é‡Œæ˜¯é‚£å¨å—¯ä¸»åŠ›\",\"group\":\"\"}\\n',\n",
       " '10082175126793|80|2024-03-01 00:12:34,687|{\"uid\":\"\",\"c\":2,\"custom\":\"{\\\\\"mod\\\\\":\\\\\"\\\\\",\\\\\"modPic\\\\\":0,\\\\\"officialTitle\\\\\":-1,\\\\\"clientTime\\\\\":\\\\\"170922315410082175126793\\\\\",\\\\\"responseData\\\\\":null,\\\\\"atData\\\\\":null,\\\\\"modid\\\\\":0}\",\"llm\":\"\",\"m\":\"ä¸‹é¢ç‚¹äº†å•Š\",\"group\":\"\"}\\n',\n",
       " '8715590962085|100|2024-03-01 00:12:34,697|{\"uid\":\"\",\"c\":2,\"custom\":\"{\\\\\"mod\\\\\":\\\\\"\\\\\",\\\\\"modPic\\\\\":0,\\\\\"officialTitle\\\\\":-1,\\\\\"clientTime\\\\\":\\\\\"17092231538715590962085\\\\\",\\\\\"responseData\\\\\":null,\\\\\"atData\\\\\":null,\\\\\"modid\\\\\":0}\",\"llm\":\"\",\"m\":\"ç°åœ¨æ²¡ä¹‹å‰é‚£ä¹ˆè´µ\",\"group\":\"\"}\\n']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# è®¾ç½®è¦é€‰å–çš„è¿ç»­å…ƒç´ çš„é•¿åº¦\n",
    "n = 10\n",
    "\n",
    "# éšæœºé€‰å–ä¸€ä¸ªèµ·å§‹ç´¢å¼•\n",
    "start_idx = random.randint(0, len(lines) - n)\n",
    "lines[start_idx:start_idx+n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a1702e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "extracted_data = []\n",
    "\n",
    "# æå–èŠå¤©çš„æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼\n",
    "pattern = r'\"m\":\"(.*?)\"'\n",
    "\n",
    "# è¿‡æ»¤å‡ºlink\n",
    "\n",
    "# éå†æ¯ä¸€è¡Œ\n",
    "for line in lines:\n",
    "    match = re.search(pattern, line)\n",
    "    if match:\n",
    "        text = match.group(1)\n",
    "        if not text.startswith('link'):\n",
    "            extracted_data.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "63cc5947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3921373"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(extracted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ac127acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# éšæœºé€‰å–ä¸€ä¸ªèµ·å§‹ç´¢å¼•\n",
    "def random_cut_arr(arr,n,seed=1):\n",
    "    random.seed(seed)\n",
    "    start_idx = random.randint(0, len(arr) - n)\n",
    "    return arr[start_idx:start_idx+n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1200d3cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['äºŒå¤§çˆºå¥½ï¼',\n",
       " 'Ù‚ÙˆÙ„',\n",
       " 'morning All ğŸ‘‹',\n",
       " \"I'm starting to understand\",\n",
       " 'Die spinnen doch',\n",
       " 'ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚',\n",
       " 'å»ç¾¤é‡Œé—®é—®å’¯',\n",
       " 'not towards our server',\n",
       " 'åäºŒç‚¹ç¡ ä¸‰ç‚¹é†’?',\n",
       " '2221çš„å‚»ç‹å­ï¼Œå¿«æ‰“å®è—ï¼Œæˆ‘åŠ«ä¸€è½¦']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_cut_arr(extracted_data,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "37876e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_extracted_data = random_cut_arr(extracted_data,500)\n",
    "text = \"\\n\".join(cut_extracted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11947a21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "aaaf37f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12814"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2aa4d925",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import BedrockChat\n",
    "from langchain_core.messages import HumanMessage,AIMessage\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder,HumanMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "34e368c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_sonnet = BedrockChat(model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\",\n",
    "                  model_kwargs={\"temperature\": 0,\n",
    "                                \"top_k\":10,\n",
    "                                \"max_tokens\": 1024,\n",
    "                                \"top_p\":0.5,\n",
    "                                # \"stop_sequences\":['</response>']\n",
    "                               },\n",
    "                  streaming=True,callbacks=[StreamingStdOutCallbackHandler()])\n",
    "\n",
    "llm_haiku = BedrockChat(model_id=\"anthropic.claude-3-haiku-20240307-v1:0\",\n",
    "                  model_kwargs={\"temperature\": 0,\n",
    "                                \"top_k\":10,\n",
    "                                \"max_tokens\": 1024,\n",
    "                                \"top_p\":0.5,\n",
    "                                # \"stop_sequences\":['</response>']\n",
    "                               },\n",
    "                  streaming=True,callbacks=[StreamingStdOutCallbackHandler()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "baee30ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_extract = \\\n",
    "\"\"\"You are an expert research assistant, tasked with identifying player sentiments regarding certain in-game items, neutral NPCs, and game market activities. \n",
    "\n",
    "Here is a document you will analyze\n",
    "<doc>\n",
    "{context}\n",
    "</doc>\n",
    "\n",
    "Here is a task:\n",
    "First, find the quotes from the document that are most relevant to {topic}, and then print them in numbered order. Quotes should be relatively short.\n",
    "If there are no relevant quotes, write \"No relevant quotes\" instead.\n",
    "please enclose your analysis results in xml tag <response>.\n",
    "\n",
    "for example:\n",
    "<response>\n",
    "1. \"æ‹å–è¡Œå¤šé¦™\" \n",
    "2. \"æˆ‘æ‹åˆ°å¥½ä¸œè¥¿äº†\" \n",
    "3. \"æ‹å–è¡Œå¤ªå·®åŠ²äº†\" \n",
    "4. \"auction sucks\" \n",
    "5. \"æ‹å–è¡Œæœ‰äººå‘åŒ…\" \n",
    "</response>\n",
    "\n",
    "Skip the preamble, go straight into the answer.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "e76207d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_sentiment = \\\n",
    "\"\"\"You are a chat message sentiment classifer\n",
    "\n",
    "Here is a document you will classify the senetiment\n",
    "<doc>\n",
    "{relevant_info}\n",
    "</doc>\n",
    "\n",
    "\n",
    "please list all the content if it is relevant to {topic} and classify the sentiment of each content into [positive,neutral,negative]'\n",
    "\n",
    "Please follow below requirements:\n",
    "1. You will strictly be based on the document in <doc>.\n",
    "2. please enclose your analysis results in xml tag <sentiment>.\n",
    "\n",
    "for example:\n",
    "<sentiment>\n",
    "1. \"æ‹å–è¡Œå¤šé¦™\" [positive]\n",
    "2. \"æˆ‘æ‹åˆ°å¥½ä¸œè¥¿äº†\" [positive]\n",
    "3. \"æ‹å–è¡Œå¤ªå·®åŠ²äº†\" [negative]\n",
    "4. \"auction sucks\" [negative]\n",
    "5. \"æ‹å–è¡Œæœ‰äººå‘åŒ…\" [neutral]\n",
    "</sentiment>\n",
    "\n",
    "Skip the preamble, go straight into the answer. \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "1add1efa-e01c-45da-8949-b85eee521677",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers.base import BaseOutputParser\n",
    "import re\n",
    "class CustOuputParser(BaseOutputParser[str]):\n",
    "\n",
    "    def extract(self,content:str) -> str:\n",
    "        pattern = r\"<response>(.*?)</response>\"\n",
    "        match = re.search(pattern, content, re.DOTALL)\n",
    "        if match:\n",
    "            text = match.group(1)\n",
    "            text = text.replace('[','(').replace(']',')') ##é¿å…è·Ÿsentimentçš„æ ¼å¼å†²çª\n",
    "            return text\n",
    "        else:\n",
    "            return 'No relevant quotes'    \n",
    "    \n",
    "    def parse(self, text: str) -> str:\n",
    "        cleaned_text = self.extract(text)\n",
    "        return cleaned_text\n",
    "\n",
    "    @property\n",
    "    def _type(self) -> str:\n",
    "        return \"cust_output_parser\"\n",
    "\n",
    "\n",
    "class CustOuputParser2(BaseOutputParser[str]):\n",
    "\n",
    "    def extract(self,content:str) -> str:\n",
    "        pattern = r\"<sentiment>(.*?)</sentiment>\"\n",
    "        match = re.search(pattern, content, re.DOTALL)\n",
    "        return match.group(1) if match else 'No sentiment'    \n",
    "    \n",
    "    def parse(self, text: str) -> str:\n",
    "        cleaned_text = self.extract(text)\n",
    "        return cleaned_text\n",
    "\n",
    "    @property\n",
    "    def _type(self) -> str:\n",
    "        return \"cust_output_parser\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea71fb61-a093-4c79-8ae0-280d6e35b910",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "3a0a50d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_chunks(arr, n):\n",
    "    chunks = []\n",
    "    for i in range(0, len(arr), n):\n",
    "        chunks.append(arr[i:i+n])\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "82656a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = split_into_chunks(extracted_data,2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "b0403acb-c13a-412d-af51-aac756552703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chunks 1961\n"
     ]
    }
   ],
   "source": [
    "print(f\"total chunks {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "f22dbfe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33601"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text =  \"\\n\".join(chunks[45])\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "038dd969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_core.output_parsers import StrOutputParser\n",
    "# prompt = ChatPromptTemplate.from_template(template)\n",
    "prompt_extract = ChatPromptTemplate.from_template(template_extract)\n",
    "prompt_sentiment = ChatPromptTemplate.from_template(template_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "1f144e41-6388-47d5-85ce-76c25c2f6745",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "from operator import itemgetter\n",
    "## å¦‚æœæ²¡æœ‰ç›¸å…³å†…å®¹åˆ™æ— é¡»invoke chain2\n",
    "def route(info):\n",
    "    if not 'no relevant quotes' in info['relevant_info'].lower():\n",
    "        return chain_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "bc312ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = CustOuputParser()\n",
    "output2_parser  = CustOuputParser2()\n",
    "\n",
    "chain_1 = prompt_extract | llm_sonnet |output_parser\n",
    "chain_2 = prompt_sentiment | llm_sonnet|output2_parser\n",
    "# chain_3 = ({'relevant_info':chain_1,'topic':itemgetter('topic')})|prompt_sentiment | llm_haiku|output2_parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "400e5a17-fecc-40ea-a35a-c26689fe6a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "##æµ‹è¯•chain3\n",
    "# chain_3.invoke({'topic':\"auction house\",\n",
    "#                        'context':text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "16ef25c2-9076-43e5-8c7c-3f072dc54a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<response>\n",
      "1. \"æœ‰äººæ€¥çœ¼äº†@[CTGC] ğŸ’•ãŠ–Never\" (Someone is legit bidding)\n",
      "2. \"æˆ‘æ‹¿æ­»å·¥èµ„çš„äºº\" (I'm putting your a ss on my front door)\n",
      "3. \"æœ‰çº¢åŒ…ï¼Œ50é’»\" (There is a red packet, 50 gems)\n",
      "4. \"è“è‰²çš„\" (A blue one)\n",
      "5. \"è°å‘çš„\" (Who sent it)\n",
      "6. \"æˆ‘æ‹·ï¼Œæˆ‘æ²¡æ‹¿åˆ°\" (I didn't get it)\n",
      "7. \"ç‚¹å¤ªå¿«ï¼Œå¥½åƒæ˜¯20é’»çŸ³\" (Clicked too fast, seems like 20 gems)\n",
      "8. \"è¿™æ˜¯æˆ˜äº‰\" (This is war)\n",
      "9. \"çœ‹åˆ°äº†\" (I saw it)\n",
      "10. \"æœ‰å¤§ä½¬å‡ºæ‰‹äº†\" (Some whale spent money)\n",
      "</response>\n",
      "<sentiment>\n",
      "1. \"æœ‰äººæ€¥çœ¼äº†@(CTGC) ğŸ’•ãŠ–Never\" [neutral]\n",
      "2. \"æˆ‘æ‹¿æ­»å·¥èµ„çš„äºº\" [negative]\n",
      "3. \"æœ‰çº¢åŒ…ï¼Œ50é’»\" [positive]\n",
      "4. \"è“è‰²çš„\" [neutral]\n",
      "5. \"è°å‘çš„\" [neutral]\n",
      "6. \"æˆ‘æ‹·ï¼Œæˆ‘æ²¡æ‹¿åˆ°\" [negative]\n",
      "7. \"ç‚¹å¤ªå¿«ï¼Œå¥½åƒæ˜¯20é’»çŸ³\" [neutral]\n",
      "8. \"è¿™æ˜¯æˆ˜äº‰\" [neutral]\n",
      "9. \"çœ‹åˆ°äº†\" [neutral]\n",
      "10. \"æœ‰å¤§ä½¬å‡ºæ‰‹äº†\" [positive]\n",
      "</sentiment>"
     ]
    }
   ],
   "source": [
    "##æµ‹è¯•åŠ å…¥äº†è·¯ç”±é€‰æ‹©çš„chainfull\n",
    "full_chain = ({'relevant_info':chain_1,'topic':itemgetter('topic')})| RunnableLambda(route)\n",
    "answer = full_chain.invoke({'topic':\"auction house\",'context':text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "2f2b0c47-2849-485e-88ef-5aeb45eeb514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1. \"æœ‰äººæ€¥çœ¼äº†@(CTGC) ğŸ’•ãŠ–Never\" [neutral]\\n2. \"æˆ‘æ‹¿æ­»å·¥èµ„çš„äºº\" [negative]\\n3. \"æœ‰çº¢åŒ…ï¼Œ50é’»\" [positive]\\n4. \"è“è‰²çš„\" [neutral]\\n5. \"è°å‘çš„\" [neutral]\\n6. \"æˆ‘æ‹·ï¼Œæˆ‘æ²¡æ‹¿åˆ°\" [negative]\\n7. \"ç‚¹å¤ªå¿«ï¼Œå¥½åƒæ˜¯20é’»çŸ³\" [neutral]\\n8. \"è¿™æ˜¯æˆ˜äº‰\" [neutral]\\n9. \"çœ‹åˆ°äº†\" [neutral]\\n10. \"æœ‰å¤§ä½¬å‡ºæ‰‹äº†\" [positive]\\n'"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "58321e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question = \"is there any content relevant to auction house?\"\n",
    "\n",
    "#'please list all the content if it is relevant and classify the sentiment of each content into [positive,neutral,negative]'\n",
    "\n",
    "# answer = chain_2.invoke({'topic':\"auction house\",\n",
    "#                        'context':text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "6087d996-eced-4012-9f71-2706b56f29db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "4ee6ca2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_and_sentiment(text) -> list:\n",
    "    pattern = r'^(.*?)\\s*\\[(.*?)\\]'\n",
    "    # pattern = r'\"(.*?)\"\\s*\\[(.*?)\\]$'\n",
    "    if not text:\n",
    "        return []\n",
    "    result = []\n",
    "    for line in text.split('\\n'):\n",
    "        match = re.match(pattern, line)\n",
    "        if match:\n",
    "            # print(match)\n",
    "            text_part = match.group(1)\n",
    "            quoted_texts = re.findall(r'\"(.*?)\"', text_part)\n",
    "            # print(quoted_texts)\n",
    "            sentiment_part = match.group(2)\n",
    "            result.append((quoted_texts[0], sentiment_part))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "dca16752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('æœ‰äººæ€¥çœ¼äº†@(CTGC) ğŸ’•ãŠ–Never', 'neutral'),\n",
       " ('æˆ‘æ‹¿æ­»å·¥èµ„çš„äºº', 'negative'),\n",
       " ('æœ‰çº¢åŒ…ï¼Œ50é’»', 'positive'),\n",
       " ('è“è‰²çš„', 'neutral'),\n",
       " ('è°å‘çš„', 'neutral'),\n",
       " ('æˆ‘æ‹·ï¼Œæˆ‘æ²¡æ‹¿åˆ°', 'negative'),\n",
       " ('ç‚¹å¤ªå¿«ï¼Œå¥½åƒæ˜¯20é’»çŸ³', 'neutral'),\n",
       " ('è¿™æ˜¯æˆ˜äº‰', 'neutral'),\n",
       " ('çœ‹åˆ°äº†', 'neutral'),\n",
       " ('æœ‰å¤§ä½¬å‡ºæ‰‹äº†', 'positive')]"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_text_and_sentiment(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "e293a756",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save a list to a local file, if the file is exist then append the list to the file\n",
    "def save_list(list,file_name):\n",
    "    with open(file_name,'a') as f:\n",
    "        for item in list:\n",
    "            f.write(\"%s\\n\" % item)\n",
    "    f.close()\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "394e3933",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save a list to a csv file using pandas, if the file is exist then append the list to the file\n",
    "import pandas as pd\n",
    "import os\n",
    "def save_to_csv(data, filename):\n",
    "    new_data = pd.DataFrame(data, columns=['text','sentiment'])\n",
    "    if os.path.isfile(filename):\n",
    "        df = pd.read_csv(filename)\n",
    "        #append data to df\n",
    "        df = pd.concat([df, new_data], ignore_index=True)\n",
    "    else:\n",
    "        df = new_data\n",
    "    df.to_csv(filename, index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd7d833",
   "metadata": {},
   "source": [
    "å¾ªç¯æ¯ä¸ªchunkè¿›è¡Œè¾“å‡º,æ¯æ¬¡è¿½åŠ åˆ°csvæ–‡ä»¶ä¿å­˜ï¼Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "53abb20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------chunk idx:238-------\n",
      "<response>\n",
      "No relevant quotes\n",
      "</response>\n",
      "extract_ret:\n",
      "[]\n",
      "---time cost 9.50108289718628 s -----\n",
      "sleep 10s for token tpm\n",
      "\n",
      "\n",
      "--------chunk idx:239-------\n",
      "<response>\n",
      "No relevant quotes\n",
      "</response>\n",
      "extract_ret:\n",
      "[]\n",
      "---time cost 8.842019081115723 s -----\n",
      "sleep 10s for token tpm\n",
      "\n",
      "\n",
      "--------chunk idx:240-------\n",
      "<response>\n",
      "No relevant quotes\n",
      "</response>\n",
      "extract_ret:\n",
      "[]\n",
      "---time cost 8.99118947982788 s -----\n",
      "sleep 10s for token tpm\n",
      "\n",
      "\n",
      "--------chunk idx:241-------\n",
      "<response>\n",
      "No relevant quotes\n",
      "</response>\n",
      "extract_ret:\n",
      "[]\n",
      "---time cost 9.16816759109497 s -----\n",
      "sleep 10s for token tpm\n",
      "\n",
      "\n",
      "--------chunk idx:242-------\n",
      "<response>\n",
      "No relevant quotes\n",
      "</response>\n",
      "extract_ret:\n",
      "[]\n",
      "---time cost 9.299543857574463 s -----\n",
      "sleep 10s for token tpm\n",
      "\n",
      "\n",
      "--------chunk idx:243-------\n",
      "<response>\n",
      "No relevant quotes\n",
      "</response>\n",
      "extract_ret:\n",
      "[]\n",
      "---time cost 9.416553974151611 s -----\n",
      "sleep 10s for token tpm\n",
      "\n",
      "\n",
      "--------chunk idx:244-------\n",
      "<response>\n",
      "No relevant quotes\n",
      "</response>\n",
      "extract_ret:\n",
      "[]\n",
      "---time cost 8.815222024917603 s -----\n",
      "sleep 10s for token tpm\n",
      "\n",
      "\n",
      "--------chunk idx:245-------\n",
      "<response>\n",
      "No relevant quotes\n",
      "</response>\n",
      "extract_ret:\n",
      "[]\n",
      "---time cost 8.801237106323242 s -----\n",
      "sleep 10s for token tpm\n",
      "\n",
      "\n",
      "--------chunk idx:246-------\n",
      "<response>\n",
      "No relevant quotes\n",
      "</response>\n",
      "extract_ret:\n",
      "[]\n",
      "---time cost 9.539794206619263 s -----\n",
      "sleep 10s for token tpm\n",
      "\n",
      "\n",
      "--------chunk idx:247-------\n",
      "<response>\n",
      "No relevant quotes\n",
      "</response>\n",
      "extract_ret:\n",
      "[]\n",
      "---time cost 11.497825145721436 s -----\n",
      "sleep 10s for token tpm\n",
      "\n",
      "\n",
      "--------chunk idx:248-------\n",
      "<response>\n",
      "No relevant quotes\n",
      "</response>\n",
      "extract_ret:\n",
      "[]\n",
      "---time cost 8.605921506881714 s -----\n",
      "sleep 10s for token tpm\n",
      "\n",
      "\n",
      "--------chunk idx:249-------\n",
      "<response>\n",
      "No relevant quotes\n",
      "</response>\n",
      "extract_ret:\n",
      "[]\n",
      "---time cost 9.070628643035889 s -----\n",
      "sleep 10s for token tpm\n",
      "\n",
      "\n",
      "--------chunk idx:250-------\n",
      "<response>\n",
      "No relevant quotes\n",
      "</response>\n",
      "extract_ret:\n",
      "[]\n",
      "---time cost 8.879228591918945 s -----\n",
      "sleep 10s for token tpm\n",
      "\n",
      "\n",
      "--------chunk idx:251-------\n",
      "<response>\n",
      "No relevant quotes\n",
      "</response>\n",
      "extract_ret:\n",
      "[]\n",
      "---time cost 8.637982845306396 s -----\n",
      "sleep 10s for token tpm\n",
      "\n",
      "\n",
      "--------chunk idx:252-------\n",
      "<response>\n",
      "No relevant quotes\n",
      "</response>\n",
      "extract_ret:\n",
      "[]\n",
      "---time cost 8.68789529800415 s -----\n",
      "sleep 10s for token tpm\n",
      "\n",
      "\n",
      "--------chunk idx:253-------\n",
      "<response>\n",
      "No relevant quotes\n",
      "</response>\n",
      "extract_ret:\n",
      "[]\n",
      "---time cost 8.602632522583008 s -----\n",
      "sleep 10s for token tpm\n",
      "\n",
      "\n",
      "--------chunk idx:254-------\n",
      "<response>\n",
      "No relevant quotes\n",
      "</response>\n",
      "extract_ret:\n",
      "[]\n",
      "---time cost 9.853103399276733 s -----\n",
      "sleep 10s for token tpm\n",
      "\n",
      "\n",
      "--------chunk idx:255-------\n",
      "<response>\n",
      "No relevant quotes\n",
      "</response>\n",
      "extract_ret:\n",
      "[]\n",
      "---time cost 9.379932880401611 s -----\n",
      "sleep 10s for token tpm\n",
      "\n",
      "\n",
      "--------chunk idx:256-------\n",
      "<response>\n",
      "No relevant quotes\n",
      "</response>\n",
      "extract_ret:\n",
      "[]\n",
      "---time cost 9.015280485153198 s -----\n",
      "sleep 10s for token tpm\n",
      "\n",
      "\n",
      "--------chunk idx:257-------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain_core/runnables/config.py:471\u001b[0m, in \u001b[0;36mget_executor_for_config\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ContextThreadPoolExecutor(\n\u001b[1;32m    469\u001b[0m     max_workers\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_concurrency\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    470\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[0;32m--> 471\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m executor\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain_core/runnables/base.py:2855\u001b[0m, in \u001b[0;36mRunnableParallel.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m   2843\u001b[0m         futures \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   2844\u001b[0m             executor\u001b[38;5;241m.\u001b[39msubmit(\n\u001b[1;32m   2845\u001b[0m                 step\u001b[38;5;241m.\u001b[39minvoke,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2853\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m key, step \u001b[38;5;129;01min\u001b[39;00m steps\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   2854\u001b[0m         ]\n\u001b[0;32m-> 2855\u001b[0m         output \u001b[38;5;241m=\u001b[39m {key: future\u001b[38;5;241m.\u001b[39mresult() \u001b[38;5;28;01mfor\u001b[39;00m key, future \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(steps, futures)}\n\u001b[1;32m   2856\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain_core/runnables/base.py:2855\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2843\u001b[0m         futures \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   2844\u001b[0m             executor\u001b[38;5;241m.\u001b[39msubmit(\n\u001b[1;32m   2845\u001b[0m                 step\u001b[38;5;241m.\u001b[39minvoke,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2853\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m key, step \u001b[38;5;129;01min\u001b[39;00m steps\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   2854\u001b[0m         ]\n\u001b[0;32m-> 2855\u001b[0m         output \u001b[38;5;241m=\u001b[39m {key: \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key, future \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(steps, futures)}\n\u001b[1;32m   2856\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/concurrent/futures/_base.py:453\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 453\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m     \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m     gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[385], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--------chunk idx:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-------\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     12\u001b[0m text \u001b[38;5;241m=\u001b[39m  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(chunk)\n\u001b[0;32m---> 13\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[43mfull_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtopic\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauction house\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                   \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcontext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m extract_ret \u001b[38;5;241m=\u001b[39m extract_text_and_sentiment(answer)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mextract_ret:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mextract_ret\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain_core/runnables/base.py:2218\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m   2216\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2217\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps):\n\u001b[0;32m-> 2218\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2219\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2220\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# mark each step as a child run\u001b[39;49;00m\n\u001b[1;32m   2221\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpatch_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2222\u001b[0m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseq:step:\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2223\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2224\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2225\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   2226\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain_core/runnables/base.py:2842\u001b[0m, in \u001b[0;36mRunnableParallel.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m   2839\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2840\u001b[0m     \u001b[38;5;66;03m# copy to avoid issues from the caller mutating the steps during invoke()\u001b[39;00m\n\u001b[1;32m   2841\u001b[0m     steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps)\n\u001b[0;32m-> 2842\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m get_executor_for_config(config) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m   2843\u001b[0m         futures \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   2844\u001b[0m             executor\u001b[38;5;241m.\u001b[39msubmit(\n\u001b[1;32m   2845\u001b[0m                 step\u001b[38;5;241m.\u001b[39minvoke,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2853\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m key, step \u001b[38;5;129;01min\u001b[39;00m steps\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   2854\u001b[0m         ]\n\u001b[1;32m   2855\u001b[0m         output \u001b[38;5;241m=\u001b[39m {key: future\u001b[38;5;241m.\u001b[39mresult() \u001b[38;5;28;01mfor\u001b[39;00m key, future \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(steps, futures)}\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/contextlib.py:153\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    151\u001b[0m     value \u001b[38;5;241m=\u001b[39m typ()\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 153\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraceback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m value\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain_core/runnables/config.py:468\u001b[0m, in \u001b[0;36mget_executor_for_config\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get an executor for a config.\u001b[39;00m\n\u001b[1;32m    460\u001b[0m \n\u001b[1;32m    461\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;124;03m    Generator[Executor, None, None]: The executor.\u001b[39;00m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    467\u001b[0m config \u001b[38;5;241m=\u001b[39m config \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[0;32m--> 468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ContextThreadPoolExecutor(\n\u001b[1;32m    469\u001b[0m     max_workers\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_concurrency\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    470\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m    471\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m executor\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/concurrent/futures/_base.py:649\u001b[0m, in \u001b[0;36mExecutor.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    648\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_val, exc_tb):\n\u001b[0;32m--> 649\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshutdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    650\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/concurrent/futures/thread.py:235\u001b[0m, in \u001b[0;36mThreadPoolExecutor.shutdown\u001b[0;34m(self, wait, cancel_futures)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads:\n\u001b[0;32m--> 235\u001b[0m         \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/threading.py:1096\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1095\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1096\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1098\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/threading.py:1116\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1116\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1117\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m   1118\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<response>\n",
      "No relevant quotes\n",
      "</response>"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in StreamingStdOutCallbackHandler.on_llm_new_token callback: ZMQError('Socket operation on non-socket')\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/langchain_core/callbacks/manager.py\", line 258, in handle_event\n",
      "    event = getattr(handler, event_name)(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/langchain_core/callbacks/streaming_stdout.py\", line 33, in on_llm_new_token\n",
      "    sys.stdout.write(token)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 694, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 590, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 694, in write\n",
      "    self._schedule_flush()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 590, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 696, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 742, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 783, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 138, in zmq.backend.cython.socket._check_closed\n",
      "zmq.error.ZMQError: Socket operation on non-socket\n",
      "Call stack:\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 761, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 83, in _worker\n",
      "    work_item.run()\n",
      "  File \"/opt/conda/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/langchain_core/runnables/base.py\", line 2218, in invoke\n",
      "    input = step.invoke(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 173, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 571, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 424, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 608, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/langchain_community/chat_models/bedrock.py\", line 270, in _generate\n",
      "    for chunk in self._stream(messages, stop, run_manager, **kwargs):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/langchain_community/chat_models/bedrock.py\", line 249, in _stream\n",
      "    for chunk in self._prepare_input_and_invoke_stream(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/langchain_community/llms/bedrock.py\", line 652, in _prepare_input_and_invoke_stream\n",
      "    run_manager.on_llm_new_token(chunk.text, chunk=chunk)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/langchain_core/callbacks/manager.py\", line 641, in on_llm_new_token\n",
      "    handle_event(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/langchain_core/callbacks/manager.py\", line 281, in handle_event\n",
      "    logger.warning(\n",
      "Message: \"Error in StreamingStdOutCallbackHandler.on_llm_new_token callback: ZMQError('Socket operation on non-socket')\"\n",
      "Arguments: ()\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "all_result = []\n",
    "filename = 'parsed_result'\n",
    "\n",
    "##æ–­ç‚¹è·³è¿‡\n",
    "skip_num =238\n",
    "for i,chunk in enumerate(chunks[:1000]):\n",
    "    if i < skip_num:\n",
    "        continue\n",
    "    t1 = time.time()\n",
    "    print(f'--------chunk idx:{i}-------')\n",
    "    text =  \"\\n\".join(chunk)\n",
    "    answer = full_chain.invoke({'topic':\"auction house\",\n",
    "                       'context':text})\n",
    "    extract_ret = extract_text_and_sentiment(answer)\n",
    "    print(f'\\nextract_ret:\\n{extract_ret}')\n",
    "    time.sleep(2)\n",
    "    print(f'---time cost {time.time()-t1} s -----\\nsleep 10s for token tpm\\n\\n')\n",
    "    if extract_ret:\n",
    "        all_result+=extract_ret\n",
    "        save_to_csv(extract_ret,filename+f\"chunk_{i}.csv\")\n",
    "        save_to_csv(extract_ret,filename+f\"_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "15f31179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "930ba9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \\\n",
    "\"\"\"\n",
    "1. \"â¤ï¸Holt euch im Auktionshaus die Geschenke ab â¤ï¸\" [positive] - This suggests getting gifts from the auction house, which is a positive sentiment.\n",
    "\n",
    "2. \"Under hot deals.\" [neutral] - This is a neutral statement referring to the \"Hot Deals\" section in the auction house.\n",
    "\n",
    "3. \"I don't see a lot of things being bid on in the auction houseâ€¦\" [negative] - This expresses a negative sentiment about not seeing many items being bid on in the auction house.\n",
    "\n",
    "4. \"Titan Gear auction\" [neutral] - This is a neutral mention of a Titan Gear auction.\n",
    "\n",
    "5. \"æœ‰ç©ºäº†å¸¦ä¸€ä¸‹æƒ§æ˜Ÿ\" [neutral] - This is a neutral request to be helped with something related to the \"Ark\" content, which may involve the auction house.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "cf1e4e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_and_sentiment(text) -> list:\n",
    "    pattern = r'^(.*?)\\s*\\[(.*?)\\]'\n",
    "    # pattern = r'\"(.*?)\"\\s*\\[(.*?)\\]$'\n",
    "    result = []\n",
    "    for line in text.split('\\n'):\n",
    "        match = re.match(pattern, line)\n",
    "        if match:\n",
    "            text_part = match.group(1)\n",
    "            quoted_texts = re.findall(r'\"(.*?)\"', text_part)\n",
    "            sentiment_part = match.group(2)\n",
    "            result.append((quoted_texts[0], sentiment_part))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ee1d4bfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('â¤ï¸Holt euch im Auktionshaus die Geschenke ab â¤ï¸', 'positive'),\n",
       " ('Under hot deals.', 'neutral'),\n",
       " (\"I don't see a lot of things being bid on in the auction houseâ€¦\",\n",
       "  'negative'),\n",
       " ('Titan Gear auction', 'neutral'),\n",
       " ('æœ‰ç©ºäº†å¸¦ä¸€ä¸‹æƒ§æ˜Ÿ', 'neutral')]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_text_and_sentiment(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41a5c66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
