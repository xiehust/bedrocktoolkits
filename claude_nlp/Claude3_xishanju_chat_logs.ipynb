{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf8765d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install boto3 langchain langchain_community -Uq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8db72ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646eecb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrock_runtime = boto3.client('bedrock-runtime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e14612",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '游戏聊天日志03.06~03.09.csv'\n",
    "df = pd.read_csv(filename)\n",
    "# with open(filename) as f:\n",
    "#     lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8faa80-8170-45bb-93b7-a032e3425f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb6f433-7cc1-42cc-9aa5-658a236684b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.channelid.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd2643b-7017-4a1a-b1f6-713d80441ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('channelid').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f821a88-e4ca-4786-a191-549fee8c596d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by=['channelid', '@timestamp'], ascending=[True, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a95ce4a-da54-4527-8a70-796af6a2a18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd96c80-1eb0-4f70-9f3e-a6ae75d51824",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_id = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f77544-4012-46cd-90e7-df2709f50986",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df['chat'] = df.apply(lambda x: f\"<channel>{'世界频道_'+str(x['channelid']) if x['channelid'] == 0 else '其他频道_'+str(x['channelid']) }<channel><username>{x['senderrolename']}</username><message>{x['_c3']}</message>\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594b9309-2daa-4cd5-b392-d0f9e43c80c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df[df.channelid==c_id]\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e218d70-47e4-484b-ac39-464d01607853",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data = list(df_new.chat.values)\n",
    "len(extracted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa4d925",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import BedrockChat\n",
    "from langchain_core.messages import HumanMessage,AIMessage\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder,HumanMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e368c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_sonnet = BedrockChat(model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\",\n",
    "                  model_kwargs={\"temperature\": 0,\n",
    "                                \"top_k\":10,\n",
    "                                \"max_tokens\": 4000,\n",
    "                                \"top_p\":0.5,\n",
    "                                # \"stop_sequences\":['</response>']\n",
    "                               },\n",
    "                  streaming=True,callbacks=[StreamingStdOutCallbackHandler()])\n",
    "\n",
    "llm_haiku = BedrockChat(model_id=\"anthropic.claude-3-haiku-20240307-v1:0\",\n",
    "                  model_kwargs={\"temperature\": 0,\n",
    "                                \"top_k\":10,\n",
    "                                \"max_tokens\": 4000,\n",
    "                                \"top_p\":0.5,\n",
    "                                # \"stop_sequences\":['</response>']\n",
    "                               },\n",
    "                  streaming=True,callbacks=[StreamingStdOutCallbackHandler()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baee30ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_extract = \\\n",
    "\"\"\"You are a great linguist classifer, and now you are asked to analyze the group chat history of users in a game, and identify the user if it is against the rules.\n",
    "The rules is defined as classes [A,B,C,D]\n",
    "Below is the definition of classes:\n",
    "- A: \"小号脚本广告\",特征有：小号高频发言、文案内容重复、点对点私聊拉人；表现形式有：私聊询问要不要做拖、或者高福利玩XXX游戏；私聊询问要不要福利；私聊免费送福利； 私聊要不要一起玩新游；私聊给激活码；\n",
    "- B: \"诱导加微拉人\",特征有：小号在世界频道或私聊以各种理由，诱导玩家加微信或者加QQ；表现形式有：小号在世界频道重复发言，说有福利码，要的私聊，私聊后要求加微信或者加QQ才给福利码；小号在世界频道收月卡号、收金币，私聊后，要求加微或者加QQ详聊；小号在世界频道说找队友一起玩游戏或者说不会玩找人教，私聊小号后，小号要求加微或者加QQ；小号在世界频道出号、免费送号、送金币，私聊后要求加微或QQ详聊；小号改名为【花的票帮找回】【氪多帮追回】等名字，在世界频道重复发言，称充值可退款，私聊要求加微信或者加QQ；\n",
    "- C: \"诱导关注公众号拉人\", 特征有：小号在世界频道或私聊诱导玩家关注公众号；表现形式有：小号在世界频道刷屏，说免费送礼包金币兑换码，诱导关注公众号；小号把名字改为带公众号的ID，说白嫖金币兑换码，诱导关注公众号；\n",
    "- D: \"工作室家族建群拉人；\", 特征有：族长/管理/小号在家族/帮会频道高频发言、文案内容重复、私聊拉人. 表现形式:族长/管理在家族/帮会/私聊频道刷屏，说马上清理机器人/一起下副本/组固定队，要求玩家进群；族长/管理在家族/帮会频道刷屏，说让玩家注意查看邮件进群；族长不发言，家族内未充值小号在家族/帮会/私聊频道以族长名义拉人进群；\n",
    "\n",
    "Here is the tasks:\n",
    "Only find the quotes from the message that are against the rules and then print them in xml tag <response>. \n",
    "Quotes should be exactly the same as original text.\n",
    "If there are no relevant quotes at all, write \"No relevant quotes\" instead.\n",
    "\n",
    "Here is a chat history you will analyze\n",
    "<doc>\n",
    "{context}\n",
    "</doc>\n",
    "\n",
    "\n",
    "please enclose your analysis results in xml tag <response>.\n",
    "\n",
    "the output format is json, for example:\n",
    "<response>\n",
    "[\n",
    "{{\"channel\":xxx,\"username\":xxx,\"message\":xxx}}\n",
    "]\n",
    "</response>\n",
    "\n",
    "\n",
    "Skip the preamble, go straight into the answer.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86afb940-1b34-470c-9046-63ee50aeae49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76207d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_sentiment = \\\n",
    "\"\"\"You are a INFORMATION classifier\n",
    "Now you are asked to analyze the group chat history of users in a game, and identify the user if it is against the rules.\n",
    "Give you a list of sentences you will classify them to the predefined classes [A,B,C,D,N], output the class in <label_class>. and output a confidence score between 0 to 10, that represents how relevant it is to the class label, 10 means most relevant, and 0 is not relevant\n",
    "Below is the definition of classes:\n",
    "- A: \"小号脚本广告\",特征有：小号高频发言、文案内容重复、点对点私聊拉人；表现形式有：私聊询问要不要做拖、或者高福利玩XXX游戏；私聊询问要不要福利；私聊免费送福利； 私聊要不要一起玩新游；私聊给激活码；愿不愿意做内部玩家，福利玩家。\n",
    "- B: \"诱导加微拉人\",特征有：小号在世界频道或私聊以各种理由，诱导玩家加微信或者加QQ；表现形式有：小号在世界频道重复发言，说有福利码，要的私聊，私聊后要求加微信或者加QQ才给福利码；小号在世界频道收月卡号、收金币，私聊后，要求加微或者加QQ详聊；小号在世界频道说找队友一起玩游戏或者说不会玩找人教，私聊小号后，小号要求加微或者加QQ；小号在世界频道出号、免费送号、送金币，私聊后要求加微或QQ详聊；小号改名为【花的票帮找回】【氪多帮追回】等名字，在世界频道重复发言，称充值可退款，私聊要求加微信或者加QQ；\n",
    "- C: \"诱导关注公众号拉人\", 特征有：小号在世界频道或私聊诱导玩家关注公众号；表现形式有：小号在世界频道刷屏，说免费送礼包金币兑换码，诱导关注公众号；小号把名字改为带公众号的ID，说白嫖金币兑换码，诱导关注公众号；\n",
    "- D: \"工作室家族建群拉人；\", 特征有：族长/管理/小号在家族/帮会频道高频发言、文案内容重复、私聊拉人. 表现形式:族长/管理在家族/帮会/私聊频道刷屏，说马上清理机器人/一起下副本/组固定队，要求玩家进群；族长/管理在家族/帮会频道刷屏，说让玩家注意查看邮件进群；族长不发言，家族内未充值小号在家族/帮会/私聊频道以族长名义拉人进群；\n",
    "- E: \"其他\"， 不符合A,B,C,D分类特征。\n",
    "\n",
    "Here are the sentences:\n",
    "<sentences>\n",
    "{relevant_info}\n",
    "</sentences>\n",
    "\n",
    "Please follow below requirements:\n",
    "1. You will strictly be based on the document in <doc>.\n",
    "2. please enclose your analysis results in xml tag <output>.\n",
    "3. output a score between 0 -10,\n",
    "\n",
    "the output format for example:\n",
    "<output>\n",
    "<channel>xxx</channel><username>xxx</username><message>xxx</message><label_class>A</label_class><score>10<score>\n",
    "</output>\n",
    "\n",
    "Skip the preamble, go straight into the answer. \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1add1efa-e01c-45da-8949-b85eee521677",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers.base import BaseOutputParser\n",
    "import re\n",
    "class CustOuputParser(BaseOutputParser[str]):\n",
    "\n",
    "    def extract(self,content:str) -> str:\n",
    "        pattern = r\"<response>(.*?)</response>\"\n",
    "        match = re.search(pattern, content, re.DOTALL)\n",
    "        if match:\n",
    "            text = match.group(1)\n",
    "            text = text.replace('[','(').replace(']',')') ##避免跟sentiment的格式冲突\n",
    "            return text\n",
    "        else:\n",
    "            return 'No relevant quotes'    \n",
    "    \n",
    "    def parse(self, text: str) -> str:\n",
    "        cleaned_text = self.extract(text)\n",
    "        return cleaned_text\n",
    "\n",
    "    @property\n",
    "    def _type(self) -> str:\n",
    "        return \"cust_output_parser\"\n",
    "\n",
    "\n",
    "class CustOuputParser2(BaseOutputParser[str]):\n",
    "\n",
    "    def extract(self,content:str) -> str:\n",
    "        pattern = r\"<output>(.*?)</output>\"\n",
    "        match = re.search(pattern, content, re.DOTALL)\n",
    "        return match.group(1) if match else 'No sentiment'    \n",
    "    \n",
    "    def parse(self, text: str) -> str:\n",
    "        cleaned_text = self.extract(text)\n",
    "        return cleaned_text\n",
    "\n",
    "    @property\n",
    "    def _type(self) -> str:\n",
    "        return \"cust_output_parser\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea71fb61-a093-4c79-8ae0-280d6e35b910",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0a50d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_chunks(arr, n):\n",
    "    chunks = []\n",
    "    for i in range(0, len(arr), n):\n",
    "        chunks.append(arr[i:i+n])\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82656a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = split_into_chunks(extracted_data,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0403acb-c13a-412d-af51-aac756552703",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"total chunks {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22dbfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text =  \"\\n\".join(chunks[0])\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038dd969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_core.output_parsers import StrOutputParser\n",
    "# prompt = ChatPromptTemplate.from_template(template)\n",
    "prompt_extract = ChatPromptTemplate.from_template(template_extract)\n",
    "prompt_sentiment = ChatPromptTemplate.from_template(template_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f144e41-6388-47d5-85ce-76c25c2f6745",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "from operator import itemgetter\n",
    "## 如果没有相关内容则无须invoke chain2\n",
    "def route(info):\n",
    "    if not 'no relevant quotes' in info['relevant_info'].lower():\n",
    "        return chain_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc312ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = CustOuputParser()\n",
    "output2_parser  = CustOuputParser2()\n",
    "\n",
    "chain_1 = prompt_extract | llm_sonnet | output_parser\n",
    "chain_2 = prompt_sentiment | llm_sonnet| output2_parser\n",
    "# chain_3 = ({'relevant_info':chain_1,'topic':itemgetter('topic')})|prompt_sentiment | llm_haiku|output2_parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400e5a17-fecc-40ea-a35a-c26689fe6a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "##测试chain3\n",
    "# chain_3.invoke({'topic':\"auction house\",\n",
    "#                        'context':text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ef25c2-9076-43e5-8c7c-3f072dc54a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "##测试加入了路由选择的chainfull\n",
    "full_chain = ({'relevant_info':chain_1})| RunnableLambda(route)\n",
    "answer = full_chain.invoke({'context':text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2b0c47-2849-485e-88ef-5aeb45eeb514",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58321e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question = \"is there any content relevant to auction house?\"\n",
    "\n",
    "#'please list all the content if it is relevant and classify the sentiment of each content into [positive,neutral,negative]'\n",
    "\n",
    "# answer = chain_2.invoke({'topic':\"auction house\",\n",
    "#                        'context':text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6087d996-eced-4012-9f71-2706b56f29db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info(text):\n",
    "    pattern = r'<channel>(.*?)</channel><username>(.*?)</username><message>(.*?)</message><label_class>(.*?)</label_class><score>(.*?)</score>'\n",
    "    matches = re.findall(pattern, text)\n",
    "    print(matches)\n",
    "    result = []\n",
    "    for match in matches:\n",
    "        # info = {\n",
    "        #     'channel': match[0],\n",
    "        #     'username': match[1],\n",
    "        #     'message': match[2],\n",
    "        #     'label_class': match[3],\n",
    "        #     'score': int(match[4])\n",
    "        # }\n",
    "        info = [match[0], match[1], match[2],  match[3], int(match[4])]\n",
    "        result.append(info)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f627af-69a3-4e48-a64d-cc11a0621d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret= extract_info(answer)\n",
    "ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e293a756",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save a list to a local file, if the file is exist then append the list to the file\n",
    "def save_list(list,file_name):\n",
    "    with open(file_name,'a') as f:\n",
    "        for item in list:\n",
    "            f.write(\"%s\\n\" % item)\n",
    "    f.close()\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394e3933",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save a list to a csv file using pandas, if the file is exist then append the list to the file\n",
    "import pandas as pd\n",
    "import os\n",
    "def save_to_csv(data, filename):\n",
    "    new_data = pd.DataFrame(data, columns=['channel', 'username', 'message', 'label_class', 'score'])\n",
    "    if os.path.isfile(filename):\n",
    "        df = pd.read_csv(filename)\n",
    "        #append data to df\n",
    "        df = pd.concat([df, new_data], ignore_index=True)\n",
    "    else:\n",
    "        df = new_data\n",
    "    df.to_csv(filename, index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd7d833",
   "metadata": {},
   "source": [
    "循环每个chunk进行输出,每次追加到csv文件保存，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53abb20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "all_result = []\n",
    "filename = f'chlid_{c_id}_parsed_result'\n",
    "\n",
    "##断点跳过\n",
    "skip_num =9\n",
    "for i,chunk in enumerate(chunks):\n",
    "    if i < skip_num:\n",
    "        continue\n",
    "    t1 = time.time()\n",
    "    print(f'--------chunk idx:{i}-------')\n",
    "    text =  \"\\n\".join(chunk)\n",
    "    answer = full_chain.invoke({\n",
    "                       'context': text})\n",
    "    extract_ret = extract_info(answer)\n",
    "    print(f'\\nextract_ret:\\n{extract_ret}')\n",
    "    time.sleep(40)\n",
    "    print(f'---time cost {time.time()-t1} s -----\\nsleep 10s for token tpm\\n\\n')\n",
    "    if extract_ret:\n",
    "        all_result+=extract_ret\n",
    "        save_to_csv(extract_ret,filename+f\"chunk_{i}.csv\")\n",
    "        save_to_csv(extract_ret,filename+f\"_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f31179",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41a5c66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
