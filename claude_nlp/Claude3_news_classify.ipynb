{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf8765d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install boto3 langchain langchain_community -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8db72ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "646eecb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrock_runtime = boto3.client('bedrock-runtime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5e14612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>标题</th>\n",
       "      <th>url</th>\n",
       "      <th>摘要</th>\n",
       "      <th>网站</th>\n",
       "      <th>作者</th>\n",
       "      <th>发布时间</th>\n",
       "      <th>是否推送</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>在AI时代，识别专属于“你”的骗局</td>\n",
       "      <td>https://www.toutiao.com/article/73338475961945...</td>\n",
       "      <td>结合“平安包头”官微等渠道披露的案件细节，《瞭望》提到的受害人可能是福州市一家科技公司的法人...</td>\n",
       "      <td>今日头条-社会</td>\n",
       "      <td>袁文泽</td>\n",
       "      <td>20240210140858</td>\n",
       "      <td>不推送</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>排队发红包了\\n[爆竹][爆竹][爆竹]\\n两个小孩压岁钱比我一个月工资还多\\n到哪说理去\\...</td>\n",
       "      <td>https://www.iesdouyin.com/share/video/73338534...</td>\n",
       "      <td>排队发红包了[爆竹][爆竹][爆竹]两个小孩压岁钱比我一个月工资还多到哪说理去😅😅😅</td>\n",
       "      <td>抖音</td>\n",
       "      <td>蓝梦雨</td>\n",
       "      <td>20240210141731</td>\n",
       "      <td>不推送</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>//@小林是李昀锐:#致1999年的自己#新岁已至，幸福常伴，天长地“九”！</td>\n",
       "      <td>https://weibo.com/7616066284/NFU8pzv7c</td>\n",
       "      <td>//@小林是李昀锐:#致1999年的自己#新岁已至，幸福常伴，天长地“九”！</td>\n",
       "      <td>新浪微博</td>\n",
       "      <td>泪下寻深冬</td>\n",
       "      <td>20240210141840</td>\n",
       "      <td>不推送</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>看看，这就是不给钱的下场，直接到他家门口堵</td>\n",
       "      <td>https://www.iesdouyin.com/share/video/73338543...</td>\n",
       "      <td>看看，这就是不给钱的下场，直接到他家门口堵</td>\n",
       "      <td>抖音</td>\n",
       "      <td>来自星星的你</td>\n",
       "      <td>20240210142056</td>\n",
       "      <td>推送</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>哈哈哈，新年就是要玩得开心‪！我也来放烟花了[馋嘴]</td>\n",
       "      <td>https://weibo.com/5972629295/NFU994YGC</td>\n",
       "      <td>哈哈哈，新年就是要玩得开心‪！我也来放烟花了[馋嘴]</td>\n",
       "      <td>新浪微博</td>\n",
       "      <td>挚爱月与歌</td>\n",
       "      <td>20240210142029</td>\n",
       "      <td>不推送</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  标题  \\\n",
       "0                                  在AI时代，识别专属于“你”的骗局   \n",
       "1  排队发红包了\\n[爆竹][爆竹][爆竹]\\n两个小孩压岁钱比我一个月工资还多\\n到哪说理去\\...   \n",
       "2             //@小林是李昀锐:#致1999年的自己#新岁已至，幸福常伴，天长地“九”！   \n",
       "3                              看看，这就是不给钱的下场，直接到他家门口堵   \n",
       "4                         哈哈哈，新年就是要玩得开心‪！我也来放烟花了[馋嘴]   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://www.toutiao.com/article/73338475961945...   \n",
       "1  https://www.iesdouyin.com/share/video/73338534...   \n",
       "2             https://weibo.com/7616066284/NFU8pzv7c   \n",
       "3  https://www.iesdouyin.com/share/video/73338543...   \n",
       "4             https://weibo.com/5972629295/NFU994YGC   \n",
       "\n",
       "                                                  摘要       网站      作者  \\\n",
       "0  结合“平安包头”官微等渠道披露的案件细节，《瞭望》提到的受害人可能是福州市一家科技公司的法人...  今日头条-社会     袁文泽   \n",
       "1         排队发红包了[爆竹][爆竹][爆竹]两个小孩压岁钱比我一个月工资还多到哪说理去😅😅😅       抖音     蓝梦雨   \n",
       "2             //@小林是李昀锐:#致1999年的自己#新岁已至，幸福常伴，天长地“九”！     新浪微博   泪下寻深冬   \n",
       "3                              看看，这就是不给钱的下场，直接到他家门口堵       抖音  来自星星的你   \n",
       "4                         哈哈哈，新年就是要玩得开心‪！我也来放烟花了[馋嘴]     新浪微博   挚爱月与歌   \n",
       "\n",
       "             发布时间 是否推送  \n",
       "0  20240210140858  不推送  \n",
       "1  20240210141731  不推送  \n",
       "2  20240210141840  不推送  \n",
       "3  20240210142056   推送  \n",
       "4  20240210142029  不推送  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'data/场景2-样本数据-2.xlsx'\n",
    "df = pd.read_excel(filename,nrows=2000)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "014749d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "102ddb24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       {\"title\":在AI时代，识别专属于“你”的骗局,\"abstract\":结合“平安包头”...\n",
       "1       {\"title\":排队发红包了\\n[爆竹][爆竹][爆竹]\\n两个小孩压岁钱比我一个月工资还...\n",
       "2       {\"title\"://@小林是李昀锐:#致1999年的自己#新岁已至，幸福常伴，天长地“九”...\n",
       "3       {\"title\":看看，这就是不给钱的下场，直接到他家门口堵,\"abstract\":看看，这...\n",
       "4       {\"title\":哈哈哈，新年就是要玩得开心‪！我也来放烟花了[馋嘴],\"abstract\"...\n",
       "                              ...                        \n",
       "1995    {\"title\":#龙年第一条微博#\\n潜龙腾跃而起 便是人间春色万里[送福] ​​,\"ab...\n",
       "1996    {\"title\":我家狗看见这些烟花就会尖叫着跑上前去，吓死我了,\"abstract\":我家...\n",
       "1997    {\"title\":借着烟花许愿 希望我们都能得偿所愿，2024龙年新春大吉#欢欢喜喜过大年 ...\n",
       "1998    {\"title\":#烟花 #大洋湾新年有好戏 排队两个多小时，就为了25分钟的烟花秀，值了,...\n",
       "1999    {\"title\":我的宝😍😍😍#我家的小暖男正在渐渐长大 #小神兽在身边 #一转眼都已经这么...\n",
       "Length: 2000, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news = df.apply(lambda x :\"{\"+f'\"title\":{x[\"标题\"]},\"abstract\":{x[\"摘要\"]},\"news_id\":{x[\"发布时间\"]}'+\"}\" ,axis=1)\n",
    "df_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2aa4d925",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import BedrockChat\n",
    "from langchain_core.messages import HumanMessage,AIMessage\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder,HumanMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34e368c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_sonnet = BedrockChat(model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\",\n",
    "                  model_kwargs={\"temperature\": 0.1,\n",
    "                                \"top_k\":250,\n",
    "                                \"max_tokens\": 4096,\n",
    "                                \"top_p\":0.5,\n",
    "                                # \"stop_sequences\":['</response>']\n",
    "                               },\n",
    "                  streaming=True,callbacks=[StreamingStdOutCallbackHandler()])\n",
    "\n",
    "llm_haiku = BedrockChat(model_id=\"anthropic.claude-3-haiku-20240307-v1:0\",\n",
    "                  model_kwargs={\"temperature\": 0.1,\n",
    "                                \"top_k\":250,\n",
    "                                \"max_tokens\": 4096,\n",
    "                                \"top_p\":0.5,\n",
    "                                # \"stop_sequences\":['</response>']\n",
    "                               },\n",
    "                  streaming=True,callbacks=[StreamingStdOutCallbackHandler()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "baee30ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_extract = \\\n",
    "\"\"\"You are a great text classifer, and now you are asked to analyze the news from internet and extract and classify the news which are fallen into categories:\n",
    "[官员舆情,司法舆情,民族舆情,暴恐舆情,经济舆情,旅游舆情,民生舆情,环境舆情,教育舆情,文化舆情,宗教舆情,自然灾害,敏感舆情,医疗舆情,人为灾害]\n",
    "Below is the definition of each category:\n",
    "官员舆情- 新闻内容涉及：独断专行,履历造假,工作作风,官商勾结,挥霍性腐败,挪用公款,公车私用,招兵黑幕,滥用职权,工作失职,官职买卖\n",
    "司法舆情- 新闻内容涉及：目无法纪,伪证假证,冤假错案,警民冲突,暴力执法,选举换届\n",
    "民族舆情 -新闻内容涉及：民族政策,民族习俗,传统节日,民族信仰\n",
    "暴恐舆情 - 新闻内容涉及：恐怖组织,自杀袭击,生化袭击,独狼式袭击\n",
    "经济舆情 - 新闻内容涉及：偷税漏税,非法生产,非法买卖,走私、造假,非法传销,证件票券犯罪,扰乱市场秩序\n",
    "旅游舆情 - 新闻内容涉及：旅游管理,旅游投诉,非法宰客,景区门票,景点设施,虚假景点\n",
    "民生舆情 - 新闻内容涉及：房屋交易,违规建筑,农资质量,食品安全,豆腐渣工程,欠薪讨薪,传染病疫情,婚育婴、养老,就业、失业、职业疾病,土地、拆迁、验收纠纷\n",
    "环境舆情 - 新闻内容涉及：生物入侵，土地污染，资源乱采，生物多样性破坏，大气污染，水体污染，水土流失，盗猎盗采\n",
    "教育舆情 - 新闻内容涉及：学生学籍，校园欺凌，校园暴力，校园安全，违规办学，教育政策，减招问题，网瘾问题，幼儿性侵，试题泄露，教育收费，学校体罚，非法补课，校风师德，校园环境，校园设施，学术造假\n",
    "文化舆情 - 新闻内容涉及：文物保护，文化政策，文化补贴，晚会演出，非物质文化遗产保护，文物展览，社会思潮，文化发展，电视电台\n",
    "宗教舆情 - 新闻内容涉及：非法传教，宗教信仰，邪教传播，宗教场所\n",
    "自然灾害 - 新闻内容涉及：洪水灾害，风灾灾害，海洋灾害，大雾灾害，高温旱灾，雨雪灾害，冻害灾害，生物灾害，地质灾害，泥石流灾害\n",
    "敏感舆情 - 新闻内容涉及：后台关系，面子工程，贪污受贿，暗箱操作，霸占问题，拐卖、盗窃，涉赌、涉黄，扰乱公共秩序，国有资产流失，抢劫、毁坏公物，危险品、涉爆、投毒，黑恶势力，绑架勒索，妨害公务，城管执法，执法不当，人身侵犯，游行示威，围堵机关，上访/抗议，自杀/自焚，暴力/涉枪\n",
    "医疗舆情 - 新闻内容涉及：医疗事故，医患关系，医疗改革，医疗设施，医疗卫生，医疗政策，违规办院，药品价格，医疗报销，挂号问题，票贩问题，患者体验，医闹纠纷，医德医风，医生技术，假药黑药\n",
    "人为灾害 - 新闻内容涉及：公路事故，水上事故，矿难事故，铁路事故，溺水事故，火灾事故，空难事故，核辐射事故，水电气事故，公共设施事故\n",
    "其他舆情 - 新闻内容涉及：其他不在以上的分类中内容\n",
    "\n",
    "Here is the tasks:\n",
    "Only find the quotes from the message that are are fallen into categories and classify them, and then print them in xml tag <response>. \n",
    "Quotes should be exactly the same as original text.\n",
    "If there are no relevant quotes at all, write \"No relevant quotes\" instead.\n",
    "\n",
    "Here is a chat history you will analyze\n",
    "<doc>\n",
    "{context}\n",
    "</doc>\n",
    "\n",
    "\n",
    "please enclose your analysis results in xml tag <response>.\n",
    "\n",
    "the output format is json, for example:\n",
    "<response>\n",
    "[\n",
    "{{\"title\":xxx,\"abstract\":xxx,\"url\":xxx,\"category\":xxx}}\n",
    "]\n",
    "</response>\n",
    "\n",
    "\n",
    "Skip the preamble, go straight into the answer.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e76207d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_sentiment = \\\n",
    "\"\"\"You are a text classifier\n",
    "Give you a list of news from internet you will classify them to the predefined categories [官员舆情,司法舆情,民族舆情,暴恐舆情,经济舆情,旅游舆情,民生舆情,环境舆情,教育舆情,文化舆情,宗教舆情,自然灾害,敏感舆情,医疗舆情,人为灾害,其他],\n",
    "output the category and a confidence score between 0 to 10, that represents how relevant it is to the category, 10 means most relevant, and 0 is not relevant. \n",
    "\n",
    "Below is the definition of each category:\n",
    "官员舆情- 新闻内容涉及：独断专行,履历造假,工作作风,官商勾结,挥霍性腐败,挪用公款,公车私用,招兵黑幕,滥用职权,工作失职,官职买卖\n",
    "司法舆情- 新闻内容涉及：目无法纪,伪证假证,冤假错案,警民冲突,暴力执法,选举换届\n",
    "民族舆情 -新闻内容涉及：民族政策,民族习俗,传统节日,民族信仰\n",
    "暴恐舆情 - 新闻内容涉及：恐怖组织,自杀袭击,生化袭击,独狼式袭击\n",
    "经济舆情 - 新闻内容涉及：偷税漏税,非法生产,非法买卖,走私、造假,非法传销,证件票券犯罪,扰乱市场秩序\n",
    "旅游舆情 - 新闻内容涉及：旅游管理,旅游投诉,非法宰客,景区门票,景点设施,虚假景点\n",
    "民生舆情 - 新闻内容涉及：房屋交易,违规建筑,农资质量,食品安全,豆腐渣工程,欠薪讨薪,传染病疫情,婚育婴、养老,就业、失业、职业疾病,土地、拆迁、验收纠纷\n",
    "环境舆情 - 新闻内容涉及：生物入侵，土地污染，资源乱采，生物多样性破坏，大气污染，水体污染，水土流失，盗猎盗采\n",
    "教育舆情 - 新闻内容涉及：学生学籍，校园欺凌，校园暴力，校园安全，违规办学，教育政策，减招问题，网瘾问题，幼儿性侵，试题泄露，教育收费，学校体罚，非法补课，校风师德，校园环境，校园设施，学术造假\n",
    "文化舆情 - 新闻内容涉及：文物保护，文化政策，文化补贴，晚会演出，非物质文化遗产保护，文物展览，社会思潮，文化发展，电视电台\n",
    "宗教舆情 - 新闻内容涉及：非法传教，宗教信仰，邪教传播，宗教场所\n",
    "自然灾害 - 新闻内容涉及：洪水灾害，风灾灾害，海洋灾害，大雾灾害，高温旱灾，雨雪灾害，冻害灾害，生物灾害，地质灾害，泥石流灾害\n",
    "敏感舆情 - 新闻内容涉及：后台关系，面子工程，贪污受贿，暗箱操作，霸占问题，拐卖、盗窃，涉赌、涉黄，扰乱公共秩序，国有资产流失，抢劫、毁坏公物，危险品、涉爆、投毒，黑恶势力，绑架勒索，妨害公务，城管执法，执法不当，人身侵犯，游行示威，围堵机关，上访/抗议，自杀/自焚，暴力/涉枪\n",
    "医疗舆情 - 新闻内容涉及：医疗事故，医患关系，医疗改革，医疗设施，医疗卫生，医疗政策，违规办院，药品价格，医疗报销，挂号问题，票贩问题，患者体验，医闹纠纷，医德医风，医生技术，假药黑药\n",
    "人为灾害 - 新闻内容涉及：公路事故，水上事故，矿难事故，铁路事故，溺水事故，火灾事故，空难事故，核辐射事故，水电气事故，公共设施事故\n",
    "其他舆情 - 新闻内容涉及：其他不在以上的分类中内容\n",
    "\n",
    "\n",
    "Here are the news:\n",
    "<news>\n",
    "{relevant_info}\n",
    "</news>\n",
    "\n",
    "Please follow below requirements:\n",
    "1. You will strictly be based on the document in <news>.\n",
    "2. please enclose your analysis results in xml tag <sentiment>.\n",
    "3. output a score between 0 -10,\n",
    "\n",
    "the output format is json for example:\n",
    "<sentiment>\n",
    "[\n",
    "{{\"title\":xxx,\"abstract\":xxx,\"category\":xxx,\"url\":xxx,\"score\":xx}}\n",
    "]\n",
    "</sentiment>\n",
    "\n",
    "Skip the preamble, go straight into the answer. \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1add1efa-e01c-45da-8949-b85eee521677",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers.base import BaseOutputParser\n",
    "import re\n",
    "class CustOuputParser(BaseOutputParser[str]):\n",
    "\n",
    "    def extract(self,content:str) -> str:\n",
    "        pattern = r\"<response>(.*?)</response>\"\n",
    "        match = re.search(pattern, content, re.DOTALL)\n",
    "        if match:\n",
    "            text = match.group(1)\n",
    "            text = text.replace('[','(').replace(']',')') ##避免跟sentiment的格式冲突\n",
    "            return text\n",
    "        else:\n",
    "            return 'No relevant quotes'    \n",
    "    \n",
    "    def parse(self, text: str) -> str:\n",
    "        cleaned_text = self.extract(text)\n",
    "        return cleaned_text\n",
    "\n",
    "    @property\n",
    "    def _type(self) -> str:\n",
    "        return \"cust_output_parser\"\n",
    "\n",
    "\n",
    "class CustOuputParser2(BaseOutputParser[str]):\n",
    "\n",
    "    def extract(self,content:str) -> str:\n",
    "        pattern = r\"<sentiment>(.*?)</sentiment>\"\n",
    "        match = re.search(pattern, content, re.DOTALL)\n",
    "        return match.group(1) if match else 'No sentiment'    \n",
    "    \n",
    "    def parse(self, text: str) -> str:\n",
    "        cleaned_text = self.extract(text)\n",
    "        return cleaned_text\n",
    "\n",
    "    @property\n",
    "    def _type(self) -> str:\n",
    "        return \"cust_output_parser\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea71fb61-a093-4c79-8ae0-280d6e35b910",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a0a50d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_chunks(arr, n):\n",
    "    chunks = []\n",
    "    for i in range(0, len(arr), n):\n",
    "        chunks.append(arr[i:i+n])\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82656a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = split_into_chunks(df_news.values,250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0403acb-c13a-412d-af51-aac756552703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chunks 8\n"
     ]
    }
   ],
   "source": [
    "print(f\"total chunks {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f22dbfe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38665\n"
     ]
    }
   ],
   "source": [
    "text =  \"\\n\".join(chunks[0])\n",
    "print(len(text))\n",
    "# print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "038dd969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_core.output_parsers import StrOutputParser\n",
    "# prompt = ChatPromptTemplate.from_template(template)\n",
    "prompt_extract = ChatPromptTemplate.from_template(template_extract)\n",
    "prompt_sentiment = ChatPromptTemplate.from_template(template_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7c348bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = CustOuputParser()\n",
    "output2_parser  = CustOuputParser2()\n",
    "\n",
    "llm = llm_haiku\n",
    "chain_1 = prompt_extract | llm |output_parser\n",
    "chain_2 = prompt_sentiment | llm|output2_parser\n",
    "# chain_3 = ({'relevant_info':chain_1,'topic':itemgetter('topic')})|prompt_sentiment | llm_haiku|output2_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f144e41-6388-47d5-85ce-76c25c2f6745",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "from operator import itemgetter\n",
    "## 如果没有相关内容则无须invoke chain2\n",
    "def route(info):\n",
    "    if not 'no relevant quotes' in info['relevant_info'].lower():\n",
    "        return chain_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16ef25c2-9076-43e5-8c7c-3f072dc54a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<response>\n",
      "[\n",
      "{\"title\":\"在AI时代，识别专属于\"你\"的骗局\",\"abstract\":\"结合\"平安包头\"官微等渠道披露的案件细节，《瞭望》提到的受害人可能是福州市一家科技公司的法人代表郭先生...去年4月，他10分钟被骗430万元的案子一度成为热搜...\",\"category\":\"经济舆情\"},\n",
      "{\"title\":\"排队发红包了\",\"abstract\":\"排队发红包了[爆竹][爆竹][爆竹]两个小孩压岁钱比我一个月工资还多到哪说理去😅😅😅\",\"category\":\"民生舆情\"},\n",
      "{\"title\":\"//@小林是李昀锐:#致1999年的自己#新岁已至，幸福常伴，天长地\"九\"！\",\"abstract\":\"//@小林是李昀锐:#致1999年的自己#新岁已至，幸福常伴，天长地\"九\"！\",\"category\":\"文化舆情\"},\n",
      "{\"title\":\"看看，这就是不给钱的下场，直接到他家门口堵\",\"abstract\":\"看看，这就是不给钱的下场，直接到他家门口堵\",\"category\":\"民生舆情\"},\n",
      "{\"title\":\"哈哈哈，新年就是要玩得开心‪！我也来放烟花了[馋嘴]\",\"abstract\":\"哈哈哈，新年就是要玩得开心‪！我也来放烟花了[馋嘴]\",\"category\":\"旅游舆情\"},\n",
      "{\"title\":\"今天2024年🌟，新的一年里Ssp护工祝福大家🎵✨✨🌵 一帆风顺⛵🎏✨✨🌷 二龙腾飞✈🚀✨✨🌺 三羊开泰🌅🎆✨✨🍀 四季平安🌈🎑✨✨🌻 五福临门😄💪✨✨🌸 六六大顺🎉\",\"abstract\":\"临门😄💪✨✨🌻 六六大顺🎉🎯✨✨🌹 七星高照🙏🎇✨✨💐 八方来财🏧💰✨✨🌷 九九同心💏🎎✨✨☀ 十全十美🙌🈵✨✨🌺 百事亨通👏🎰✨✨🌺 千事吉祥🉐☀✨✨🍀 万事如意🎐👍✨✨好运连连[福][烟花....\",\"category\":\"民生舆情\"},\n",
      "{\"title\":\"寻人启事 丁样香，绰名张红，身高1米5，体重180 斤，身穿黑色到膝盖下左右衣服，衣服带 帽子，黑色裤子，黑色面包鞋，带一个双 肩黑兰色背包，户籍江苏省东台市许可镇 西灶村三组，于20\",\"abstract\":\"寻人启事 丁样香，绰名张红，身高1米5，体重180 斤，身穿黑色到膝盖下左右衣服，衣服带 帽子，黑色裤子，黑色面包鞋，带一个双 肩黑兰色背包，户籍江苏省东台市许可镇 西灶村三组，于2024年1月20日上午11 时36分从吉林市龙潭区铁东化工A3小区 家里离走，至今未归...家里有两个\",\"category\":\"民生舆情\"},\n",
      "{\"title\":\"人找车目的南通或者上海\",\"abstract\":\"人找车目的南通或者上海OCR:IMG:中华人民共和国想动 证号 超白满友 佳址 中国 123号 江苏省盐城 出生日期 市公安局....\",\"category\":\"民生舆情\"},\n",
      "{\"title\":\"大纵湖景区 可预订2月10号-24号门票 去不了随时可退 无任何手续费 大纵湖春节上演千架无人机表演\",\"abstract\":\"大纵湖景区 可预订2月10号-24号门票 去不了随时可退 无任何手续费 大纵湖春节上演千架无人机表演\",\"category\":\"旅游舆情\"},\n",
      "{\"title\":\"#天南地北大拜年#除夕的烟花\",\"abstract\":\"#天南地北大拜年#除夕的烟花\",\"category\":\"文化舆情\"},\n",
      "{\"title\":\"春节长假去看海鸥吧！这份出行妙招要收好\",\"abstract\":\"春天不出游枉费好时光而春天不在春城出游就更加浪费了春节小长假不妨带上你的家人和这群小精灵一起享受昆明的蓝天白云吧春节长假看海鸥这份出行妙招要收好↓↓↓落客通道 分流管控为确保观鸥群众出行安全，提升市民、游客的观鸥体验，在周六、周日及法定节假日等观鸥高峰时段，昆明交警对海埂大坝片区采取了分流管控措施...\",\"category\":\"旅游舆情\"},\n",
      "{\"title\":\"扬州离婚律师咨询方式盐城律师咨询电话盐城东台律师盐城刑事律师盐城离婚律师盐城交通事故律师盐城东台律师维护您的合法权益 #南京交通事故律师地址 #扬州交通事故律师在线咨询 #北京刑事律师咨询方式 #泰州\",\"abstract\":\"扬州离婚律师咨询方式盐城律师咨询电话盐城东台律师盐城刑事律师盐城离婚律师盐城交通事故律师盐城东台律师维护您的合法权益 #南京交通事故律师地址 #扬州交通事故律师在线咨询 #北京刑事律师咨询方式 #泰州地址 #扬州在线咨询 OCR:IMG:离婚后母亲可以更改孩子的姓氏吗... 对于子女姓氏，我国《民法\",\"category\":\"司法舆情\"},\n",
      "{\"title\":\"哈哈哈，新年就是要玩得开心‪！我也来放烟花了[馋嘴]\",\"abstract\":\"哈哈哈，新年就是要玩得开心‪！我也来放烟花了[馋嘴]\",\"category\":\"旅游舆情\"},\n",
      "{\"title\":\"无标题\",\"abstract\":\"\",\"category\":\"其他舆情\"},\n",
      "{\"title\":\"新春献词\",\"abstract\":\"中共建湖县委建湖县人民政府（2024年2月10日）玉兔呈祥辞岁去，金龙贺新迎春来...在这辞旧迎新的喜庆时刻，中共建湖县委、建湖县人民政府谨向全县人民，向驻湖部队全体指战员、武警官兵、公安干警，向长期以来关心支持建湖经济社会发展的各界人士，向节日期间坚守岗位的同志们，致以诚挚的问候和新春的祝福...\",\"category\":\"民生舆情\"},\n",
      "{\"title\":\"不好意思金骆驼血液中心连锁，所以啊科室只有医生主任护士长在…\",\"abstract\":\"不好意思金骆驼血液中心连锁，所以啊科室只有医生主任护士长在……大家都叫医生主任是海门……所以王总和张总没有在科室，说是在盐城....\",\"category\":\"医疗舆情\"},\n",
      "{\"title\":\"我们这更搞笑，昨晚没说禁止燃放烟花爆竹。今天白天在群里发个通知。[捂脸]\",\"abstract\":\"我们这更搞笑，昨晚没说禁止燃放烟花爆竹。今天白天在群里发个通知。[捂脸]\",\"category\":\"民生舆情\"},\n",
      "{\"title\":\"#新年祝福 玥玥发个视频给各位好友们拜年了！[庆祝][庆祝][烟花][烟花][烟花][烟花]#过年啦过年啦\",\"abstract\":\"#新年祝福 玥玥发个视频给各位好友们拜年了！[庆祝][庆祝][烟花][烟花][烟花][烟花]#过年啦过年啦\",\"category\":\"文化舆情\"},\n",
      "{\"title\":\"人找车目的南通或者上海\",\"abstract\":\"人找车目的南通或者上海OCR:IMG:中华人民共和国动有 Driving 证号 姓名 白满友 国销 Mionale中国 佳址 江苏省盐城市阜宁县陈集镇钟左村一组...Addres 123号 江苏省盐城 出生月期1981-05-25 Date ofBir 市公安局.... Addres 123号 江苏\",\"category\":\"民生舆情\"},\n",
      "{\"title\":\"#顾家家居 #爆竹声声辞旧岁 #家具 #放烟花也要有仪式感 #一起放烟花 过年啦，恭祝大家新年快乐！龙年大吉！\",\"abstract\":\"#顾家家居 #爆竹声声辞旧岁 #家具 #放烟花也要有仪式感 #一起放烟花 过年啦，恭祝大家新年快乐！龙年大吉！\",\"category\":\"文化舆情\"},\n",
      "{\"title\":\"春节海报文案合集\",\"abstract\":\"初 七 事业稳健步步升 势起 T.037156199999 地址：郑州航空港区梅河路与黄海路交叉口IMG:迎来一年好开局 满满一盘大桔 吃大桔，大吉大利 学业、事业、家业无往不利 少壮派，有滋有味过大年 保利和府 约87-170m军工滨海....\",\"category\":\"文化舆情\"},\n",
      "{\"title\":\"达美乐来射阳，其它披萨店都得倒闭[捂脸]\",\"abstract\":\"达美乐来射阳，其它披萨店都得倒闭[捂脸]\",\"category\":\"经济舆情\"},\n",
      "{\"title\":\"...\",\"abstract\":\"...OCR:IMG:爆竹伴着欢笑声 烟花....\",\"category\":\"文化舆情\"},\n",
      "{\"title\":\"一群死碧阳的，死表子养的来给东台老百姓添堵了，不会开早点把本子注销掉\",\"abstract\":\"一群死碧阳的，死表子养的来给东台老百姓添堵了，不会开早点把本子注销掉\",\"category\":\"民生舆情\"},\n",
      "{\"title\":\"草堰口镇#开往春天的列车\",\"abstract\":\"草堰口镇#开往春天的列车OCR:IMG:草堰口镇高铁站 中国第一个乡镇高铁站 从北上广深云贵川回草堰口镇不再堵车了 盐城市草堰口站 草户高站\",\"category\":\"民生舆情\"},\n",
      "{\"title\":\"昨天晚上烟花不断，我玩了棒棒糖🍭嘻嘻\",\"abstract\":\"昨天晚上烟花不断，我玩了棒棒糖🍭嘻嘻\",\"category\":\"文化舆情\"},\n",
      "{\"title\":\"大年初一堵车快乐哈😊\",\"abstract\":\"大年初一堵车快乐哈😊\",\"category\":\"民生舆情\"},\n",
      "{\"title\":\"盐城哪来的取暖费？搞笑呢吧，我工作这么多年，就没领过降温费和取暖费，到底谁真谁假？\",\"abstract\":\"盐城哪来的取暖费？搞笑呢吧，我工作这么多年，就没领过降温费和取暖费，到底谁真谁假？\",\"category\":\"民生舆情\"},\n",
      "{\"title\":\"一口气看个爽系列，耗时19小时制作 #漫画解说\",\"abstract\":\"一口气看个爽系列，耗时19小时制作 #漫画解说OCR:IMG:阿音漫漫 种美女叫做富婆 钉妖剑 飘一 想公~ 客栈 轰 挪 giegie 所以我把 御兽. 战 杀人啦 蜜~ 塞 福 不仅家没了 哦哦哦 b bb 竟然出现 幻觉 bBP 出鞘 滋 黄渝动漫 菜 死吧...大事 峰~ 而林毅制造的谣言 收...\",\"category\":\"文化舆情\"},\n",
      "{\"title\":\"...\",\"abstract\":\"...OCR:IMG:长爆竹伴养欢笑声 烟花....\",\"category\":\"文化舆情\"},\n",
      "{\"title\":\"...\",\"abstract\":\"...OCR:IMG:爆竹伴着欢笑声 烟花伴随着快乐卡 春联写满来年大半设 大红包教满幸福快 一家人欢聚一堂笑开颜...IMG:大年 爆竹伴着欢笑声响 烟花....IMG:大年 爆竹伴着欢笑声响 烟花伴随着快乐飞 春联写满来年大半 大红包效满幸福快 家人欢漾一堂笑开颜IMG:除之刘 大年 人生感 爆\",\"category\":\"文化舆情\"},\n",
      "{\"title\":\"在我模糊的记忆里 只有你最清晰\",\"abstract\":\"在我模糊的记忆里 只有你最清晰OCR:IMG:096110 阜宁县公安局通价施份划警务室IMG:粤96110 阜宁县公安局通榆路智慧警务室IMG:粤96110 阜宁县公安局通榆路智慧警务室\",\"category\":\"民生舆情\"},\n",
      "{\"title\":\"盐渎街道为数不多的抗美援朝老战士@"
     ]
    }
   ],
   "source": [
    "##测试加入了路由选择的chainfull\n",
    "full_chain = ({'relevant_info':chain_1,})| RunnableLambda(route)\n",
    "answer = full_chain.invoke({'context':text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2b0c47-2849-485e-88ef-5aeb45eeb514",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58321e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question = \"is there any content relevant to auction house?\"\n",
    "\n",
    "#'please list all the content if it is relevant and classify the sentiment of each content into [positive,neutral,negative]'\n",
    "\n",
    "# answer = chain_2.invoke({'topic':\"auction house\",\n",
    "#                        'context':text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6087d996-eced-4012-9f71-2706b56f29db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee6ca2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_and_sentiment(text) -> list:\n",
    "    pattern = r'^(.*?)\\s*\\[(.*?)\\]'\n",
    "    # pattern = r'\"(.*?)\"\\s*\\[(.*?)\\]$'\n",
    "    if not text:\n",
    "        return []\n",
    "    result = []\n",
    "    for line in text.split('\\n'):\n",
    "        match = re.match(pattern, line)\n",
    "        if match:\n",
    "            # print(match)\n",
    "            text_part = match.group(1)\n",
    "            quoted_texts = re.findall(r'\"(.*?)\"', text_part)\n",
    "            # print(quoted_texts)\n",
    "            sentiment_part = match.group(2)\n",
    "            result.append((quoted_texts[0], sentiment_part))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca16752",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_text_and_sentiment(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e293a756",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save a list to a local file, if the file is exist then append the list to the file\n",
    "def save_list(list,file_name):\n",
    "    with open(file_name,'a') as f:\n",
    "        for item in list:\n",
    "            f.write(\"%s\\n\" % item)\n",
    "    f.close()\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394e3933",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save a list to a csv file using pandas, if the file is exist then append the list to the file\n",
    "import pandas as pd\n",
    "import os\n",
    "def save_to_csv(data, filename):\n",
    "    new_data = pd.DataFrame(data, columns=['text','sentiment'])\n",
    "    if os.path.isfile(filename):\n",
    "        df = pd.read_csv(filename)\n",
    "        #append data to df\n",
    "        df = pd.concat([df, new_data], ignore_index=True)\n",
    "    else:\n",
    "        df = new_data\n",
    "    df.to_csv(filename, index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd7d833",
   "metadata": {},
   "source": [
    "循环每个chunk进行输出,每次追加到csv文件保存，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53abb20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "all_result = []\n",
    "filename = 'parsed_result'\n",
    "\n",
    "##断点跳过\n",
    "skip_num =238\n",
    "for i,chunk in enumerate(chunks[:1000]):\n",
    "    if i < skip_num:\n",
    "        continue\n",
    "    t1 = time.time()\n",
    "    print(f'--------chunk idx:{i}-------')\n",
    "    text =  \"\\n\".join(chunk)\n",
    "    answer = full_chain.invoke({'topic':\"auction house\",\n",
    "                       'context':text})\n",
    "    extract_ret = extract_text_and_sentiment(answer)\n",
    "    print(f'\\nextract_ret:\\n{extract_ret}')\n",
    "    time.sleep(2)\n",
    "    print(f'---time cost {time.time()-t1} s -----\\nsleep 10s for token tpm\\n\\n')\n",
    "    if extract_ret:\n",
    "        all_result+=extract_ret\n",
    "        save_to_csv(extract_ret,filename+f\"chunk_{i}.csv\")\n",
    "        save_to_csv(extract_ret,filename+f\"_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f31179",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41a5c66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
