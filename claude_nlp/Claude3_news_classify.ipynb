{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf8765d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install boto3 langchain langchain_community -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8db72ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "646eecb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrock_runtime = boto3.client('bedrock-runtime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a5e14612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>标题</th>\n",
       "      <th>url</th>\n",
       "      <th>摘要</th>\n",
       "      <th>网站</th>\n",
       "      <th>作者</th>\n",
       "      <th>发布时间</th>\n",
       "      <th>是否推送</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>在AI时代，识别专属于“你”的骗局</td>\n",
       "      <td>https://www.toutiao.com/article/73338475961945...</td>\n",
       "      <td>结合“平安包头”官微等渠道披露的案件细节，《瞭望》提到的受害人可能是福州市一家科技公司的法人...</td>\n",
       "      <td>今日头条-社会</td>\n",
       "      <td>袁文泽</td>\n",
       "      <td>20240210140858</td>\n",
       "      <td>不推送</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>排队发红包了\\n[爆竹][爆竹][爆竹]\\n两个小孩压岁钱比我一个月工资还多\\n到哪说理去\\...</td>\n",
       "      <td>https://www.iesdouyin.com/share/video/73338534...</td>\n",
       "      <td>排队发红包了[爆竹][爆竹][爆竹]两个小孩压岁钱比我一个月工资还多到哪说理去😅😅😅</td>\n",
       "      <td>抖音</td>\n",
       "      <td>蓝梦雨</td>\n",
       "      <td>20240210141731</td>\n",
       "      <td>不推送</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>//@小林是李昀锐:#致1999年的自己#新岁已至，幸福常伴，天长地“九”！</td>\n",
       "      <td>https://weibo.com/7616066284/NFU8pzv7c</td>\n",
       "      <td>//@小林是李昀锐:#致1999年的自己#新岁已至，幸福常伴，天长地“九”！</td>\n",
       "      <td>新浪微博</td>\n",
       "      <td>泪下寻深冬</td>\n",
       "      <td>20240210141840</td>\n",
       "      <td>不推送</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>看看，这就是不给钱的下场，直接到他家门口堵</td>\n",
       "      <td>https://www.iesdouyin.com/share/video/73338543...</td>\n",
       "      <td>看看，这就是不给钱的下场，直接到他家门口堵</td>\n",
       "      <td>抖音</td>\n",
       "      <td>来自星星的你</td>\n",
       "      <td>20240210142056</td>\n",
       "      <td>推送</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>哈哈哈，新年就是要玩得开心‪！我也来放烟花了[馋嘴]</td>\n",
       "      <td>https://weibo.com/5972629295/NFU994YGC</td>\n",
       "      <td>哈哈哈，新年就是要玩得开心‪！我也来放烟花了[馋嘴]</td>\n",
       "      <td>新浪微博</td>\n",
       "      <td>挚爱月与歌</td>\n",
       "      <td>20240210142029</td>\n",
       "      <td>不推送</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  标题  \\\n",
       "0                                  在AI时代，识别专属于“你”的骗局   \n",
       "1  排队发红包了\\n[爆竹][爆竹][爆竹]\\n两个小孩压岁钱比我一个月工资还多\\n到哪说理去\\...   \n",
       "2             //@小林是李昀锐:#致1999年的自己#新岁已至，幸福常伴，天长地“九”！   \n",
       "3                              看看，这就是不给钱的下场，直接到他家门口堵   \n",
       "4                         哈哈哈，新年就是要玩得开心‪！我也来放烟花了[馋嘴]   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://www.toutiao.com/article/73338475961945...   \n",
       "1  https://www.iesdouyin.com/share/video/73338534...   \n",
       "2             https://weibo.com/7616066284/NFU8pzv7c   \n",
       "3  https://www.iesdouyin.com/share/video/73338543...   \n",
       "4             https://weibo.com/5972629295/NFU994YGC   \n",
       "\n",
       "                                                  摘要       网站      作者  \\\n",
       "0  结合“平安包头”官微等渠道披露的案件细节，《瞭望》提到的受害人可能是福州市一家科技公司的法人...  今日头条-社会     袁文泽   \n",
       "1         排队发红包了[爆竹][爆竹][爆竹]两个小孩压岁钱比我一个月工资还多到哪说理去😅😅😅       抖音     蓝梦雨   \n",
       "2             //@小林是李昀锐:#致1999年的自己#新岁已至，幸福常伴，天长地“九”！     新浪微博   泪下寻深冬   \n",
       "3                              看看，这就是不给钱的下场，直接到他家门口堵       抖音  来自星星的你   \n",
       "4                         哈哈哈，新年就是要玩得开心‪！我也来放烟花了[馋嘴]     新浪微博   挚爱月与歌   \n",
       "\n",
       "             发布时间 是否推送  \n",
       "0  20240210140858  不推送  \n",
       "1  20240210141731  不推送  \n",
       "2  20240210141840  不推送  \n",
       "3  20240210142056   推送  \n",
       "4  20240210142029  不推送  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'data/场景2-样本数据-2.xlsx'\n",
    "df = pd.read_excel(filename,nrows=2000)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "014749d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "102ddb24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       {\"title\":在AI时代，识别专属于“你”的骗局,\"abstract\":结合“平安包头”...\n",
       "1       {\"title\":排队发红包了\\n[爆竹][爆竹][爆竹]\\n两个小孩压岁钱比我一个月工资还...\n",
       "2       {\"title\"://@小林是李昀锐:#致1999年的自己#新岁已至，幸福常伴，天长地“九”...\n",
       "3       {\"title\":看看，这就是不给钱的下场，直接到他家门口堵,\"abstract\":看看，这...\n",
       "4       {\"title\":哈哈哈，新年就是要玩得开心‪！我也来放烟花了[馋嘴],\"abstract\"...\n",
       "                              ...                        \n",
       "1995    {\"title\":#龙年第一条微博#\\n潜龙腾跃而起 便是人间春色万里[送福] ​​,\"ab...\n",
       "1996    {\"title\":我家狗看见这些烟花就会尖叫着跑上前去，吓死我了,\"abstract\":我家...\n",
       "1997    {\"title\":借着烟花许愿 希望我们都能得偿所愿，2024龙年新春大吉#欢欢喜喜过大年 ...\n",
       "1998    {\"title\":#烟花 #大洋湾新年有好戏 排队两个多小时，就为了25分钟的烟花秀，值了,...\n",
       "1999    {\"title\":我的宝😍😍😍#我家的小暖男正在渐渐长大 #小神兽在身边 #一转眼都已经这么...\n",
       "Length: 2000, dtype: object"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news = df.apply(lambda x :\"{\"+f'\"title\":{x[\"标题\"]},\"abstract\":{x[\"摘要\"]},\"news_id\":{x[\"发布时间\"]}'+\"}\" ,axis=1)\n",
    "df_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2aa4d925",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import BedrockChat\n",
    "from langchain_core.messages import HumanMessage,AIMessage\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder,HumanMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "34e368c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_sonnet = BedrockChat(model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\",\n",
    "                  model_kwargs={\"temperature\": 0.1,\n",
    "                                \"top_k\":250,\n",
    "                                \"max_tokens\": 4096,\n",
    "                                \"top_p\":0.5,\n",
    "                                # \"stop_sequences\":['</response>']\n",
    "                               },\n",
    "                  streaming=True,callbacks=[StreamingStdOutCallbackHandler()])\n",
    "\n",
    "llm_haiku = BedrockChat(model_id=\"anthropic.claude-3-haiku-20240307-v1:0\",\n",
    "                  model_kwargs={\"temperature\": 0.1,\n",
    "                                \"top_k\":250,\n",
    "                                \"max_tokens\": 4096,\n",
    "                                \"top_p\":0.5,\n",
    "                                # \"stop_sequences\":['</response>']\n",
    "                               },\n",
    "                  streaming=True,callbacks=[StreamingStdOutCallbackHandler()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "baee30ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_extract = \\\n",
    "\"\"\"You are a great text classifer, and now you are asked to analyze the news from internet and extract and classify the news which are fallen into categories:\n",
    "[官员舆情,司法舆情,民族舆情,暴恐舆情,经济舆情,旅游舆情,民生舆情,环境舆情,教育舆情,文化舆情,宗教舆情,自然灾害,敏感舆情,医疗舆情,人为灾害]\n",
    "Below is the definition of each category:\n",
    "官员舆情- 新闻内容涉及：独断专行,履历造假,工作作风,官商勾结,挥霍性腐败,挪用公款,公车私用,招兵黑幕,滥用职权,工作失职,官职买卖\n",
    "司法舆情- 新闻内容涉及：目无法纪,伪证假证,冤假错案,警民冲突,暴力执法,选举换届\n",
    "民族舆情 -新闻内容涉及：民族政策,民族习俗,传统节日,民族信仰\n",
    "暴恐舆情 - 新闻内容涉及：恐怖组织,自杀袭击,生化袭击,独狼式袭击\n",
    "经济舆情 - 新闻内容涉及：偷税漏税,非法生产,非法买卖,走私、造假,非法传销,证件票券犯罪,扰乱市场秩序\n",
    "旅游舆情 - 新闻内容涉及：旅游管理,旅游投诉,非法宰客,景区门票,景点设施,虚假景点\n",
    "民生舆情 - 新闻内容涉及：房屋交易,违规建筑,农资质量,食品安全,豆腐渣工程,欠薪讨薪,传染病疫情,婚育婴、养老,就业、失业、职业疾病,土地、拆迁、验收纠纷\n",
    "环境舆情 - 新闻内容涉及：生物入侵，土地污染，资源乱采，生物多样性破坏，大气污染，水体污染，水土流失，盗猎盗采\n",
    "教育舆情 - 新闻内容涉及：学生学籍，校园欺凌，校园暴力，校园安全，违规办学，教育政策，减招问题，网瘾问题，幼儿性侵，试题泄露，教育收费，学校体罚，非法补课，校风师德，校园环境，校园设施，学术造假\n",
    "文化舆情 - 新闻内容涉及：文物保护，文化政策，文化补贴，晚会演出，非物质文化遗产保护，文物展览，社会思潮，文化发展，电视电台\n",
    "宗教舆情 - 新闻内容涉及：非法传教，宗教信仰，邪教传播，宗教场所\n",
    "自然灾害 - 新闻内容涉及：洪水灾害，风灾灾害，海洋灾害，大雾灾害，高温旱灾，雨雪灾害，冻害灾害，生物灾害，地质灾害，泥石流灾害\n",
    "敏感舆情 - 新闻内容涉及：后台关系，面子工程，贪污受贿，暗箱操作，霸占问题，拐卖、盗窃，涉赌、涉黄，扰乱公共秩序，国有资产流失，抢劫、毁坏公物，危险品、涉爆、投毒，黑恶势力，绑架勒索，妨害公务，城管执法，执法不当，人身侵犯，游行示威，围堵机关，上访/抗议，自杀/自焚，暴力/涉枪\n",
    "医疗舆情 - 新闻内容涉及：医疗事故，医患关系，医疗改革，医疗设施，医疗卫生，医疗政策，违规办院，药品价格，医疗报销，挂号问题，票贩问题，患者体验，医闹纠纷，医德医风，医生技术，假药黑药\n",
    "人为灾害 - 新闻内容涉及：公路事故，水上事故，矿难事故，铁路事故，溺水事故，火灾事故，空难事故，核辐射事故，水电气事故，公共设施事故\n",
    "其他舆情 - 新闻内容涉及：其他不在以上的分类中内容\n",
    "\n",
    "Here is the tasks:\n",
    "Only find the quotes from the message that are are fallen into categories and classify them, and then print them in xml tag <response>. \n",
    "Quotes should be exactly the same as original text.\n",
    "If there are no relevant quotes at all, write \"No relevant quotes\" instead.\n",
    "\n",
    "Here is a chat history you will analyze\n",
    "<doc>\n",
    "{context}\n",
    "</doc>\n",
    "\n",
    "\n",
    "please enclose your analysis results in xml tag <response>.\n",
    "\n",
    "the output format is json, for example:\n",
    "<response>\n",
    "[\n",
    "{{\"title\":xxx,\"abstract\":xxx,\"url\":xxx,\"category\":xxx}}\n",
    "]\n",
    "</response>\n",
    "\n",
    "\n",
    "Skip the preamble, go straight into the answer.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e76207d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_sentiment = \\\n",
    "\"\"\"You are a text classifier\n",
    "Give you a list of news from internet you will classify them to the predefined categories [官员舆情,司法舆情,民族舆情,暴恐舆情,经济舆情,旅游舆情,民生舆情,环境舆情,教育舆情,文化舆情,宗教舆情,自然灾害,敏感舆情,医疗舆情,人为灾害,其他],\n",
    "output the category and a confidence score between 0 to 10, that represents how relevant it is to the category, 10 means most relevant, and 0 is not relevant. \n",
    "\n",
    "Below is the definition of each category:\n",
    "官员舆情- 新闻内容涉及：独断专行,履历造假,工作作风,官商勾结,挥霍性腐败,挪用公款,公车私用,招兵黑幕,滥用职权,工作失职,官职买卖\n",
    "司法舆情- 新闻内容涉及：目无法纪,伪证假证,冤假错案,警民冲突,暴力执法,选举换届\n",
    "民族舆情 -新闻内容涉及：民族政策,民族习俗,传统节日,民族信仰\n",
    "暴恐舆情 - 新闻内容涉及：恐怖组织,自杀袭击,生化袭击,独狼式袭击\n",
    "经济舆情 - 新闻内容涉及：偷税漏税,非法生产,非法买卖,走私、造假,非法传销,证件票券犯罪,扰乱市场秩序\n",
    "旅游舆情 - 新闻内容涉及：旅游管理,旅游投诉,非法宰客,景区门票,景点设施,虚假景点\n",
    "民生舆情 - 新闻内容涉及：房屋交易,违规建筑,农资质量,食品安全,豆腐渣工程,欠薪讨薪,传染病疫情,婚育婴、养老,就业、失业、职业疾病,土地、拆迁、验收纠纷\n",
    "环境舆情 - 新闻内容涉及：生物入侵，土地污染，资源乱采，生物多样性破坏，大气污染，水体污染，水土流失，盗猎盗采\n",
    "教育舆情 - 新闻内容涉及：学生学籍，校园欺凌，校园暴力，校园安全，违规办学，教育政策，减招问题，网瘾问题，幼儿性侵，试题泄露，教育收费，学校体罚，非法补课，校风师德，校园环境，校园设施，学术造假\n",
    "文化舆情 - 新闻内容涉及：文物保护，文化政策，文化补贴，晚会演出，非物质文化遗产保护，文物展览，社会思潮，文化发展，电视电台\n",
    "宗教舆情 - 新闻内容涉及：非法传教，宗教信仰，邪教传播，宗教场所\n",
    "自然灾害 - 新闻内容涉及：洪水灾害，风灾灾害，海洋灾害，大雾灾害，高温旱灾，雨雪灾害，冻害灾害，生物灾害，地质灾害，泥石流灾害\n",
    "敏感舆情 - 新闻内容涉及：后台关系，面子工程，贪污受贿，暗箱操作，霸占问题，拐卖、盗窃，涉赌、涉黄，扰乱公共秩序，国有资产流失，抢劫、毁坏公物，危险品、涉爆、投毒，黑恶势力，绑架勒索，妨害公务，城管执法，执法不当，人身侵犯，游行示威，围堵机关，上访/抗议，自杀/自焚，暴力/涉枪\n",
    "医疗舆情 - 新闻内容涉及：医疗事故，医患关系，医疗改革，医疗设施，医疗卫生，医疗政策，违规办院，药品价格，医疗报销，挂号问题，票贩问题，患者体验，医闹纠纷，医德医风，医生技术，假药黑药\n",
    "人为灾害 - 新闻内容涉及：公路事故，水上事故，矿难事故，铁路事故，溺水事故，火灾事故，空难事故，核辐射事故，水电气事故，公共设施事故\n",
    "其他舆情 - 新闻内容涉及：其他不在以上的分类中内容\n",
    "\n",
    "\n",
    "Here are the news:\n",
    "<news>\n",
    "{relevant_info}\n",
    "</news>\n",
    "\n",
    "Please follow below requirements:\n",
    "1. You will strictly be based on the document in <news>.\n",
    "2. please enclose your analysis results in xml tag <sentiment>.\n",
    "3. output a score between 0 -10,\n",
    "\n",
    "the output format is json for example:\n",
    "<sentiment>\n",
    "[\n",
    "{{\"title\":xxx,\"abstract\":xxx,\"category\":xxx,\"url\":xxx,\"score\":xx}}\n",
    "]\n",
    "</sentiment>\n",
    "\n",
    "Skip the preamble, go straight into the answer. \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1add1efa-e01c-45da-8949-b85eee521677",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers.base import BaseOutputParser\n",
    "import re\n",
    "class CustOuputParser(BaseOutputParser[str]):\n",
    "\n",
    "    def extract(self,content:str) -> str:\n",
    "        pattern = r\"<response>(.*?)</response>\"\n",
    "        match = re.search(pattern, content, re.DOTALL)\n",
    "        if match:\n",
    "            text = match.group(1)\n",
    "            text = text.replace('[','(').replace(']',')') ##避免跟sentiment的格式冲突\n",
    "            return text\n",
    "        else:\n",
    "            return 'No relevant quotes'    \n",
    "    \n",
    "    def parse(self, text: str) -> str:\n",
    "        cleaned_text = self.extract(text)\n",
    "        return cleaned_text\n",
    "\n",
    "    @property\n",
    "    def _type(self) -> str:\n",
    "        return \"cust_output_parser\"\n",
    "\n",
    "\n",
    "class CustOuputParser2(BaseOutputParser[str]):\n",
    "\n",
    "    def extract(self,content:str) -> str:\n",
    "        pattern = r\"<sentiment>(.*?)</sentiment>\"\n",
    "        match = re.search(pattern, content, re.DOTALL)\n",
    "        return match.group(1) if match else 'No sentiment'    \n",
    "    \n",
    "    def parse(self, text: str) -> str:\n",
    "        cleaned_text = self.extract(text)\n",
    "        return cleaned_text\n",
    "\n",
    "    @property\n",
    "    def _type(self) -> str:\n",
    "        return \"cust_output_parser\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea71fb61-a093-4c79-8ae0-280d6e35b910",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3a0a50d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_chunks(arr, n):\n",
    "    chunks = []\n",
    "    for i in range(0, len(arr), n):\n",
    "        chunks.append(arr[i:i+n])\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "82656a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = split_into_chunks(df_news.values,250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b0403acb-c13a-412d-af51-aac756552703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chunks 8\n"
     ]
    }
   ],
   "source": [
    "print(f\"total chunks {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f22dbfe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49419\n"
     ]
    }
   ],
   "source": [
    "text =  \"\\n\".join(chunks[0])\n",
    "print(len(text))\n",
    "# print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "038dd969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_core.output_parsers import StrOutputParser\n",
    "# prompt = ChatPromptTemplate.from_template(template)\n",
    "prompt_extract = ChatPromptTemplate.from_template(template_extract)\n",
    "prompt_sentiment = ChatPromptTemplate.from_template(template_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f7c348bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = CustOuputParser()\n",
    "output2_parser  = CustOuputParser2()\n",
    "\n",
    "llm = llm_haiku\n",
    "chain_1 = prompt_extract | llm |output_parser\n",
    "chain_2 = prompt_sentiment | llm|output2_parser\n",
    "# chain_3 = ({'relevant_info':chain_1,'topic':itemgetter('topic')})|prompt_sentiment | llm_haiku|output2_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1f144e41-6388-47d5-85ce-76c25c2f6745",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "from operator import itemgetter\n",
    "## 如果没有相关内容则无须invoke chain2\n",
    "def route(info):\n",
    "    if not 'no relevant quotes' in info['relevant_info'].lower():\n",
    "        return chain_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "16ef25c2-9076-43e5-8c7c-3f072dc54a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<response>\n",
      "[\n",
      "{\"title\":\"在AI时代，识别专属于\"你\"的骗局\",\"abstract\":\"结合\"平安包头\"官微等渠道披露的案件细节，《瞭望》提到的受害人可能是福州市一家科技公司的法人代表郭先生...去年4月，他10分钟被骗430万元的案子一度成为热搜...\",\"url\":\"https://www.toutiao.com/article/7333847596194513442/\",\"category\":\"经济舆情\"},\n",
      "{\"title\":\"排队发红包了\\n[爆竹][爆竹][爆竹]\\n两个小孩压岁钱比我一个月工资还多\\n到哪说理去\\n😅😅😅\",\"abstract\":\"排队发红包了[爆竹][爆竹][爆竹]两个小孩压岁钱比我一个月工资还多到哪说理去😅😅😅\",\"url\":\"https://www.iesdouyin.com/share/video/7333853477874994441\",\"category\":\"民生舆情\"},\n",
      "{\"title\":\"看看，这就是不给钱的下场，直接到他家门口堵\",\"abstract\":\"看看，这就是不给钱的下场，直接到他家门口堵\",\"url\":\"https://www.iesdouyin.com/share/video/7333854339234139432\",\"category\":\"民生舆情\"},\n",
      "{\"title\":\"寻人启事 丁样香，绰名张红，身高1米5，体重180 斤，身穿黑色到膝盖下左右衣服，衣服带 帽子，黑色裤子，黑色面包鞋，带一个双 肩黑兰色背包，户籍江苏省东台市许可镇 西灶村三组，于20\",\"abstract\":\"寻人启事 丁样香，绰名张红，身高1米5，体重180 斤，身穿黑色到膝盖下左右衣服，衣服带 帽子，黑色裤子，黑色面包鞋，带一个双 肩黑兰色背包，户籍江苏省东台市许可镇 西灶村三组，于2024年1月20日上午11 时36分从吉林市龙潭区铁东化工A3小区 家里离走，至今未归...家里有两个\",\"url\":\"https://www.iesdouyin.com/share/video/7333854050477198629\",\"category\":\"民生舆情\"},\n",
      "{\"title\":\"人找车目的南通或者上海\",\"abstract\":\"人找车目的南通或者上海OCR:IMG:中华人民共和国想动 证号 超白满友 佳址 中国 123号 江苏省盐城 出生日期 市公安局....\",\"url\":\"https://www.toutiao.com/w/7333853954322795814/\",\"category\":\"民生舆情\"},\n",
      "{\"title\":\"大纵湖景区 可预订2月10号-24号门票 去不了随时可退 无任何手续费 大纵湖春节上演千架无人机表演\",\"abstract\":\"大纵湖景区 可预订2月10号-24号门票 去不了随时可退 无任何手续费 大纵湖春节上演千架无人机表演\",\"url\":\"https://www.iesdouyin.com/share/video/7333854734513671460\",\"category\":\"旅游舆情\"},\n",
      "{\"title\":\"扬州离婚律师咨询方式盐城律师咨询电话盐城东台律师盐城刑事律师盐城离婚律师盐城交通事故律师盐城东台律师维护您的合法权益 #南京交通事故律师地址 #扬州交通事故律师在线咨询 #北京刑事律师咨询方式 #泰州\",\"abstract\":\"扬州离婚律师咨询方式盐城律师咨询电话盐城东台律师盐城刑事律师盐城离婚律师盐城交通事故律师盐城东台律师维护您的合法权益 #南京交通事故律师地址 #扬州交通事故律师在线咨询 #北京刑事律师咨询方式 #泰州地址 #扬州在线咨询 OCR:IMG:离婚后母亲可以更改孩子的姓氏吗... 对于子女姓氏，我国《民法\",\"url\":\"https://www.iesdouyin.com/share/video/7333854976197790988\",\"category\":\"司法舆情\"},\n",
      "{\"title\":\"不好意思金骆驼血液中心连锁，所以啊科室只有医生主任护士长在…\",\"abstract\":\"不好意思金骆驼血液中心连锁，所以啊科室只有医生主任护士长在……大家都叫医生主任是海门……所以王总和张总没有在科室，说是在盐城....\",\"url\":\"https://www.xiaohongshu.com/discovery/item/65c70e60000000000a013242\",\"category\":\"医疗舆情\"},\n",
      "{\"title\":\"我们这更搞笑，昨晚没说禁止燃放烟花爆竹。今天白天在群里发个通知。[捂脸]\",\"abstract\":\"我们这更搞笑，昨晚没说禁止燃放烟花爆竹。今天白天在群里发个通知。[捂脸]\",\"url\":\"https://www.iesdouyin.com/share/video/7333811176847002914\",\"category\":\"民生舆情\"},\n",
      "{\"title\":\"达美乐来射阳，其它披萨店都得倒闭[捂脸]\",\"abstract\":\"达美乐来射阳，其它披萨店都得倒闭[捂脸]\",\"url\":\"https://www.iesdouyin.com/share/video/7333175808682446143\",\"category\":\"经济舆情\"},\n",
      "{\"title\":\"一群死碧阳的，死表子养的来给东台老百姓添堵了，不会开早点把本子注销掉\",\"abstract\":\"一群死碧阳的，死表子养的来给东台老百姓添堵了，不会开早点把本子注销掉\",\"url\":\"https://www.iesdouyin.com/share/video/7333854823072222498\",\"category\":\"民生舆情\"},\n",
      "{\"title\":\"草堰口镇#开往春天的列车\",\"abstract\":\"草堰口镇#开往春天的列车OCR:IMG:草堰口镇高铁站 中国第一个乡镇高铁站 从北上广深云贵川回草堰口镇不再堵车了 盐城市草堰口站 草户高站\",\"url\":\"https://www.iesdouyin.com/share/video/7333854374139055399\",\"category\":\"经济舆情\"},\n",
      "{\"title\":\"盐城哪来的取暖费？搞笑呢吧，我工作这么多年，就没领过降温费和取暖费，到底谁真谁假？\",\"abstract\":\"盐城哪来的取暖费？搞笑呢吧，我工作这么多年，就没领过降温费和取暖费，到底谁真谁假？\",\"url\":\"https://www.toutiao.com/w/1790492027877379/\",\"category\":\"民生舆情\"},\n",
      "{\"title\":\"在我模糊的记忆里 只有你最清晰\",\"abstract\":\"在我模糊的记忆里 只有你最清晰OCR:IMG:096110 阜宁县公安局通价施份划警务室IMG:粤96110 阜宁县公安局通榆路智慧警务室IMG:粤96110 阜宁县公安局通榆路智慧警务室\",\"url\":\"https://www.kuaishou.com/short-video/3xztqqvaxik4mi9\",\"category\":\"民生舆情\"},\n",
      "{\"title\":\"盐渎街道为数不多的抗美援朝老战士@老家邻居大嗲嗲\",\"abstract\":\"盐渎街道为数不多的抗美援朝老战士@老家邻居大嗲嗲\",\"url\":\"https://www.iesdouyin.com/share/video/7333856666695388442\",\"category\":\"民生舆情\"},\n",
      "{\"title\":\"推广淄博经验\\n 促进社会稳定\",\"abstract\":\"正当全国各地交警严查电瓶车、赢来骂声一片万民痛斥的时候，山东淄博提出三不原则，不禁行、不扣车、不罚款，也就是执法不搞一刀切，一切从人民利益出发：没有上牌的，现场免费为你安装上牌...我们盐城市大丰区更应该走在学习推广淄博经验的前列，在人民群众心目中打造人民交警为人民的良好形象...没有戴头盔的，为了\",\"url\":\"https://weitoutiao.zjurl.cn/ugc/share/wap/comment/7333751218898469668/\",\"category\":\"民生舆情\"},\n",
      "{\"title\":\"新年快乐家人们[爱你] 盐城·建湖 ​​\",\"abstract\":\"新年快乐家人们[爱你] 盐城·建湖 ​​OCR:IMG:oor 卤蛋IMG:国丰烟花 小金鱼 XIAOJINYU 浏阳市国丰烟花贸易有限公司 8167771\",\"url\":\"https://weibo.com/7344751515/NFUekxnX0\",\"category\":\"民生舆情\"},\n",
      "{\"title\":\"草堰口镇#开往春天的列车 #高铁🚅 #每个人都在奔赴各自不同的人生 新年快乐，龙年大吉！\",\"abstract\":\"#开往春天的列车 #高铁🚅 #每个人都在奔赴各自不同的人生 新年快乐，龙年大吉！OCR:IMG:车客运总 数力桥 兴隆装饰城 应绣一品值赖 中交美庐城 红红旗桥 恒达世纪新城 康平路小学 康宁小区东门 飞达路中学 新东苑小区 看守所 温地公园 就即服务中心 荣润理邦饭面 碧桂园北口 大丰人民医购\",\"url\":\"https://www.iesdouyin.com/share/video/7333863499648584998\",\"category\":\"经济舆情\"},\n",
      "{\"title\":\"不许侮辱我们响水[看][看][看]\",\"abstract\":\"不许侮辱我们响水[看][看][看]\",\"url\":\"https://www.iesdouyin.com/share/video/7333821221026450726\",\"category\":\"民族舆情\"},\n",
      "{\"title\":\"推广淄博经验\\n 促进社会稳定\",\"abstract\":\"正当全国各地交警严查电瓶车、赢来骂声一片万民痛斥的时候，山东淄博提出三不原则，不禁行、不扣车、不罚款，也就是执法不搞一刀切，一切从人民利益出发：没有上牌的，现场免费为你安装上牌...我们盐城市大丰区更应该走在学习推广淄博经验的前列，在人民群众心目中打造人民交警为人民的良好形象...没有戴头盔的，为了\",\"url\":\"https://weitoutiao.zjurl.cn/ugc/share/wap/comment/7333751218898469668/\",\"category\":\"民生舆情\"},\n",
      "{\"title\":\"盐城哪来的取暖费？搞笑呢吧，我工作这么多年，就没领过降温费和取暖费，到底谁真谁假？\",\"abstract\":\"盐城哪来的取暖费？搞笑呢吧，我工作这么多年，就没领过降温费和取暖费，到底谁真谁假？\",\"url\":\"https://www.toutiao.com/w/1790492027877379/\",\"category\":\"民生舆情\"},\n",
      "{\"title\":\"拖欠农民工工资\",\"abstract\":\"2023年9月13日在江苏省无锡市宜兴市雁行路某楼盘，苏*建设做油漆维修工...中途借生活费2000元...\",\"url\":\"http://liuyan.people.com.cn/threads/content?tid=19858194\",\"category\":\"民生舆情\"},\n",
      "{\"title\":\"骗子。南京某一学校老师（是盐城人现在工作在南京），真的恶心至极。我当初因为工作原因要将狗狗送走，我就联系盐城一家宠物店帮忙找主人。宠物店帮忙推荐了好几个，我选择了她，我当时就看她是老师，应该素质还好，\",\"abstract\":\"南京某一学校老师（是盐城人现在工作在南京），真的恶心至极...我当初因为工作原因要将狗狗送走，我就联系盐城一家宠物店帮忙找主人...宠物店帮忙推荐了好几个，我选择了她，我当时就看她是老师，应该素质还好，而且他家里也有狗狗有养狗经验，并且她自己也说又大量时间可以养狗...我叫她给我拍狗狗视频的时候，没有理睬...\",\"url\":\"https://www.iesdouyin.com/share/video/7333858154339421492\",\"category\":\"民生舆情\"},\n",
      "{\"title\":\"感谢中国好邻居，把我家路占了\",\"abstract\":\"感谢中国好邻居，把我家路占了OCR:IMG:请我们的新巨村的干部 领导看看这个羊肠小路 怎么走，汽车进不了 一走一脚烂泥\",\"url\":\"https://www.iesdouyin.com/share/video/7333861779975441683\",\"category\":\"民生舆情\"},\n",
      "{\"title\":\"不许侮辱我们响水[看][看][看]\",\"abstract\":\"不许侮辱我们响水[看][看][看]\",\"url\":\"https://www.iesdouyin.com/share/video/7333821221026450726\",\"category\":\"民族舆情\"},\n",
      "{\"title\":\"拖欠农民工工资\",\"abstract\":\"2023年9月13日在江苏省无锡市宜兴市雁行路某楼盘，苏*建设做油漆维修工...中途借生活费2"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[93], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m##测试加入了路由选择的chainfull\u001b[39;00m\n\u001b[1;32m      2\u001b[0m full_chain \u001b[38;5;241m=\u001b[39m ({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelevant_info\u001b[39m\u001b[38;5;124m'\u001b[39m:chain_1,})\u001b[38;5;241m|\u001b[39m RunnableLambda(route)\n\u001b[0;32m----> 3\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[43mfull_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcontext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pyautogen/lib/python3.10/site-packages/langchain_core/runnables/base.py:2415\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m   2413\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2414\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps):\n\u001b[0;32m-> 2415\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2416\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2417\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# mark each step as a child run\u001b[39;49;00m\n\u001b[1;32m   2418\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpatch_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2419\u001b[0m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseq:step:\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2420\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2421\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2422\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   2423\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pyautogen/lib/python3.10/site-packages/langchain_core/runnables/base.py:3060\u001b[0m, in \u001b[0;36mRunnableParallel.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m   3047\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m get_executor_for_config(config) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m   3048\u001b[0m         futures \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   3049\u001b[0m             executor\u001b[38;5;241m.\u001b[39msubmit(\n\u001b[1;32m   3050\u001b[0m                 step\u001b[38;5;241m.\u001b[39minvoke,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3058\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m key, step \u001b[38;5;129;01min\u001b[39;00m steps\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   3059\u001b[0m         ]\n\u001b[0;32m-> 3060\u001b[0m         output \u001b[38;5;241m=\u001b[39m {key: future\u001b[38;5;241m.\u001b[39mresult() \u001b[38;5;28;01mfor\u001b[39;00m key, future \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(steps, futures)}\n\u001b[1;32m   3061\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   3062\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pyautogen/lib/python3.10/site-packages/langchain_core/runnables/base.py:3060\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   3047\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m get_executor_for_config(config) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m   3048\u001b[0m         futures \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   3049\u001b[0m             executor\u001b[38;5;241m.\u001b[39msubmit(\n\u001b[1;32m   3050\u001b[0m                 step\u001b[38;5;241m.\u001b[39minvoke,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3058\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m key, step \u001b[38;5;129;01min\u001b[39;00m steps\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   3059\u001b[0m         ]\n\u001b[0;32m-> 3060\u001b[0m         output \u001b[38;5;241m=\u001b[39m {key: \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key, future \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(steps, futures)}\n\u001b[1;32m   3061\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   3062\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pyautogen/lib/python3.10/concurrent/futures/_base.py:453\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 453\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pyautogen/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##测试加入了路由选择的chainfull\n",
    "full_chain = ({'relevant_info':chain_1,})| RunnableLambda(route)\n",
    "answer = full_chain.invoke({'context':text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2b0c47-2849-485e-88ef-5aeb45eeb514",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58321e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question = \"is there any content relevant to auction house?\"\n",
    "\n",
    "#'please list all the content if it is relevant and classify the sentiment of each content into [positive,neutral,negative]'\n",
    "\n",
    "# answer = chain_2.invoke({'topic':\"auction house\",\n",
    "#                        'context':text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6087d996-eced-4012-9f71-2706b56f29db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee6ca2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_and_sentiment(text) -> list:\n",
    "    pattern = r'^(.*?)\\s*\\[(.*?)\\]'\n",
    "    # pattern = r'\"(.*?)\"\\s*\\[(.*?)\\]$'\n",
    "    if not text:\n",
    "        return []\n",
    "    result = []\n",
    "    for line in text.split('\\n'):\n",
    "        match = re.match(pattern, line)\n",
    "        if match:\n",
    "            # print(match)\n",
    "            text_part = match.group(1)\n",
    "            quoted_texts = re.findall(r'\"(.*?)\"', text_part)\n",
    "            # print(quoted_texts)\n",
    "            sentiment_part = match.group(2)\n",
    "            result.append((quoted_texts[0], sentiment_part))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca16752",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_text_and_sentiment(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e293a756",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save a list to a local file, if the file is exist then append the list to the file\n",
    "def save_list(list,file_name):\n",
    "    with open(file_name,'a') as f:\n",
    "        for item in list:\n",
    "            f.write(\"%s\\n\" % item)\n",
    "    f.close()\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394e3933",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save a list to a csv file using pandas, if the file is exist then append the list to the file\n",
    "import pandas as pd\n",
    "import os\n",
    "def save_to_csv(data, filename):\n",
    "    new_data = pd.DataFrame(data, columns=['text','sentiment'])\n",
    "    if os.path.isfile(filename):\n",
    "        df = pd.read_csv(filename)\n",
    "        #append data to df\n",
    "        df = pd.concat([df, new_data], ignore_index=True)\n",
    "    else:\n",
    "        df = new_data\n",
    "    df.to_csv(filename, index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd7d833",
   "metadata": {},
   "source": [
    "循环每个chunk进行输出,每次追加到csv文件保存，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53abb20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "all_result = []\n",
    "filename = 'parsed_result'\n",
    "\n",
    "##断点跳过\n",
    "skip_num =238\n",
    "for i,chunk in enumerate(chunks[:1000]):\n",
    "    if i < skip_num:\n",
    "        continue\n",
    "    t1 = time.time()\n",
    "    print(f'--------chunk idx:{i}-------')\n",
    "    text =  \"\\n\".join(chunk)\n",
    "    answer = full_chain.invoke({'topic':\"auction house\",\n",
    "                       'context':text})\n",
    "    extract_ret = extract_text_and_sentiment(answer)\n",
    "    print(f'\\nextract_ret:\\n{extract_ret}')\n",
    "    time.sleep(2)\n",
    "    print(f'---time cost {time.time()-t1} s -----\\nsleep 10s for token tpm\\n\\n')\n",
    "    if extract_ret:\n",
    "        all_result+=extract_ret\n",
    "        save_to_csv(extract_ret,filename+f\"chunk_{i}.csv\")\n",
    "        save_to_csv(extract_ret,filename+f\"_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f31179",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41a5c66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
